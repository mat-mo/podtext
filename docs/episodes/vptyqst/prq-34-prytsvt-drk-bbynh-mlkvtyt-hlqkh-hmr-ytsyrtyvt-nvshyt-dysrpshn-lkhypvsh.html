<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>פרק 34: פריצות דרך בבינה מלאכותית, הלקח המר, יצירתיות אנושית, דיסראפשן לחיפוש - פודטקסט</title>
    <link rel="stylesheet" href="../../styles.css">
    <script defer src="../../search.js"></script>
</head>
<body>
    <div class="container">
        <header class="site-header">
            <div class="logo">
                <a href="../../index.html">פודטקסט</a>
            </div>
            
            <div class="search-box">
                <input type="text" id="search-input" placeholder="חיפוש...">
                <div id="search-results" class="search-results hidden"></div>
            </div>

            <nav class="main-nav">
                <a href="../../index.html" class="nav-link">פרקים אחרונים</a>
                <a href="../../podcasts.html" class="nav-link">כל הפודקאסטים</a>
                <a href="../../rss.xml" class="rss-link" title="RSS">
                    <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg>
                </a>
            </nav>
        </header>

        <main>
            
    <div class="episode-header">
        <h1>פרק 34: פריצות דרך בבינה מלאכותית, הלקח המר, יצירתיות אנושית, דיסראפשן לחיפוש</h1>
        <div class="meta-row">
            <span class="meta-date">פורסם ב: 4 בנובמבר 2024</span>
            <a href="../../podcasts/vptyqst.html" class="meta-feed">אופטיקאסט</a>
        </div>
    </div>

    <div class="player-container">
        <audio id="audio-player" controls>
            <source src="https://anchor.fm/s/f116bc18/podcast/play/93941265/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-10-4%2F20118ffd-c4df-eaa7-34d7-4d97ee13cb90.mp3" type="audio/mpeg">
            Your browser does not support the audio element.
        </audio>
    </div>

    <div class="transcript-container" id="transcript">
        
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">00:00</span>
                </div>
                <div class="content">
                    <p>היי, אני אבי נתן זינגר וטוב שחזרתם לאופטיקאסט. הרבה הכרזות היו ב-AI לאחרונה, אז את הפרק הזה אנחנו נתחיל עם קצת רקע היסטורי על רשתות נוירונים, על חברת DeepMind ו-OpenAI, ואז נגיע לדבר גם על ההתפתחויות היותר עדכניות. וכרגיל, הכל פה למטרות לימודיות בלבד, שום דבר זה לא ייעוץ השקעות, אין המלצות לבצע פעולות בניירות ערך כאן, וקדימה לפרק מספר 34.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">00:25</span>
                </div>
                <div class="content">
                    <p>אפשר להגיד שפריצת הדרך הייתה כבר ב-2007 בכנס NIPS של סוף אותה שנה. ג'פרי הינטון, שבחודש שעבר הוכרז כזוכה פרס נובל, העביר הרצאה תחת הכותרת "רשתות נוירונים עמוקות" (Deep Neural Networks). לקונספט החדש הוא קרא Deep Learning (למידה עמוקה), ואת שאר הטכניקות שהיו נפוצות בזמנו הוא כינה פשוט Shallow Learning (למידה שטחית). ההתפתחויות ב-Deep Learning של תחילת שנות ה-2000 הביאו לסיום תקופה ממושכת של מה שקראו לו AI Winter (חורף גרעיני ב-AI).</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">00:55</span>
                </div>
                <div class="content">
                    <p>את השימוש הראשון ברשתות נוירונים מייחסים למכונת ה-Perceptron שנבנתה כבר ב-1957 על ידי חוקר בשם פרנק רוזנבלט במעבדה של אוניברסיטת קורנל ובמימון של הצי האמריקאי. היא נועדה כבר בשנות ה-50 לזהות עצמים ואותיות בתמונות, והמאמר שכתבו עליה אז בניו-יורקר שהכריז עליה בתור מעין "מוח מכני" שהולך להתחרות במוח האנושי. אבל למרות ההבטחות הגדולות וכל ההתלהבות, המכונה הזאת הפכה להיות די שנויה במחלוקת כי היו לה ביצועים מאוד חלשים וגם כמה מגבלות מאוד בסיסיות במודל הזה, שהובילו חוקרים מובילים בתחום לקבוע שהגישה הזאת לא הולכת לעבוד.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">01:29</span>
                </div>
                <div class="content">
                    <p>היה חוקר בשם מרווין מינסקי שהיה מאוד קולני עם הביקורת שלו וממש פירסם ספר ב-1969 שכביכול הוכיח שכל הרעיון הזה של הפרספטרון ורשתות נוירונים נכשלו. זה סתם את הגולל על כל הנושא של רשתות נוירונים למשך כמה עשורים. אבל את ג'פרי הינטון זה לא שיכנע. הוא התחיל את לימודי הדוקטורט שלו בשנות ה-70, בדיוק כשהתייבשו תקציבי המחקר לטובת AI. הם קוצצו בגלל האכזבה מהפער האדיר שהיו בין הציפיות מהטכנולוגיה לבין הביצועים המאוד בסיסיים שהצליחה להציג.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">02:00</span>
                </div>
                <div class="content">
                    <p>אבל הינטון היה בטוח שהוא רואה משהו שכולם מפספסים, שהספר של מינסקי לא באמת הבין את הרעיון מאחורי המודל של רוזנבלט, והינטון האמין גם שאת הבעיות שהיו עם המודל הזה היה אפשר לפתור. הוא המשיך לדמיין מודל שידמה את האופן שבו עובד המוח האנושי. ומכונת הפרספטרון הייתה רק שכבה אחת של נוירונים, אבל מה אם היה אפשר לבנות רשת שמורכבת מכמה שכבות? ומה אם יהיה אלגוריתם שקובע באופן אוטומטי מה צריכים להיות הקשרים בין כל הנוירונים האלה והמשקל שצריך לייחס לכל אחד מהם?</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">02:25</span>
                </div>
                <div class="content">
                    <p>באחד הקורסים שעשיתי בסטנפורד היה פרופסור מבוגר שהקפיד להזכיר שאת כל האלגוריתמים והטכניקות שהוא מלמד פיתחו כבר בשנות ה-80, אבל עכשיו נתנו לזה שם סקסי כמו Deep Learning והוא אמר שפתאום כולכם נרשמים לקורס. מה שהיה חסר עדיין בשנות ה-80, מעבר לפיתוח המתמטי, היה כוח חישוב שיאפשר להריץ את הטכניקות האלה על פני רשתות נוירונים מספיק גדולות עם כמויות משמעותיות של מידע. בתחילת שנות ה-2000 התברר שהמעבדים הגרפיים של Nvidia, שבמקור תוכננו כדי להאיץ חישוב של גרפיקה ממוחשבת, יכולים להתאים מאוד גם כדי להאיץ אימון של רשת נוירונים.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">03:10</span>
                </div>
                <div class="content">
                    <p>לי דנג היה מנהל מחקר AI במיקרוסופט. הצוות שלו עבד שלוש שנים כדי לבנות מערכת לזיהוי דיבור (Speech Recognition) שעדיין התקשתה להציג שיפור משמעותי לעומת המערכת הקודמת שהייתה במיקרוסופט. ב-2008 הוא נתקל בג'פרי הינטון שהתלהב מזה שרשתות נוירונים לטענתו התחילו לעבוד טוב על דיבור. דנג היה מאוד סקפטי כי הינטון לא היה מומחה לזיהוי דיבור ורשתות נוירונים מעולם לא עבדו טוב על שום דבר מאז שנות ה-50. ובכל זאת דנג השתכנע להזמין את הינטון למעבדה שלו ברדמונד, ואחרי כמה שעות של לכתוב קוד ביחד היה להם כבר פרוטוטייפ שהציג ביצועים לא רעים בזיהוי דיבור. הוא היה כל כך הרבה יותר פשוט ואלגנטי ממערכות שכללו אוסף ענק של חוקים שנכתבו באופן ידני.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">04:09</span>
                </div>
                <div class="content">
                    <p>ההתקדמות שלהם נתקעה כשדנג התקשה להשיג אישור לרכוש את המעבדים הגרפיים שהינטון ביקש כדי להמשיך את הפרויקט. כל GPU עלה 10,000 דולר והמנהלים של דנג התנגדו לבזבז כסף על ציוד של משחקי מחשב בשביל מחקר של AI. אבל דנג התעקש ובסוף הצליח להשיג את התקציב. ואז שני סטודנטים לדוקטורט מהמעבדה של הינטון הצליחו לבנות במיקרוסופט תוך כמה חודשים ספורים מערכת זיהוי דיבור שהייתה הרבה יותר טובה מכל מה שמחלקת המחקר כולה של מיקרוסופט בנתה בכל העשור שלפני כן.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">04:39</span>
                </div>
                <div class="content">
                    <p>הבאה בתור הייתה גוגל. אחרי שנפטרו גם שם בעיות של הרמת גבה סביב דרישות רכש של GPUs, היה דוקטורנט אחר מהמעבדה של הינטון שהצטרף בתור אינטרן כדי לאמן בגוגל רשת נוירונים. תוך שבוע אחד המערכת החדשה כבר הציגה ביצועים יותר טובים מאשר שירות זיהוי הדיבור שרץ בתור חלק ממערכת ההפעלה אנדרואיד, והמערכת החדשה הזאת החליפה את השירות הישן תוך כמה חודשים. הייתה עוד מערכת שהם אימנו שם כדי לזהות ולחפש מילים בתוך סרטוני יוטיוב, שדי מהר הציגה תוצאות כל כך טובות שלא היה אפשר להאמין שזה אמיתי. מסתבר שחוץ מתקציב ל-GPUs, עוד יתרון של חברות האינטרנט הגדולות הייתה שיש להן המון המון דאטה שאפשר לאמן עליו את רשתות הנוירונים האלה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">05:25</span>
                </div>
                <div class="content">
                    <p>קצת אחר כך רשתות נוירונים התחילו לעבוד טוב גם על תמונות (Computer Vision). הרעיון והחזון היו של איליה סוצקבר שהיה סטודנט במעבדה של הינטון, והביצוע היה של אלכס קריז'בסקי שהתמחה באמנות האפלה של תכנות אלגוריתמים למעבדים גרפיים. ב-2012 המערכת שלהם, AlexNet, הציגה ביצועים שומטי לסתות באתגר של זיהוי תמונות בסקייל נרחב על מאגר בשם ImageNet. אחוז השגיאה ש-AlexNet השיגה היה 15% לעומת מעל 26% למערכת שהגיעה במקום השני בתחרות. העולם הבין שרשתות נוירונים הן כן שימושיות אחרי הכל, זה פשוט לקח להם כמה עשורים להגיע לבשלות. שנה אחרי AlexNet גוגל רכשה את הסטארט-אפ שהינטון הקים יחד עם סוצקבר וקריז'בסקי ב-44 מיליון דולר. ב-2013 44 מיליון דולר עוד נחשב הרבה כסף בשביל סטארט-אפ AI.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">06:15</span>
                </div>
                <div class="content">
                    <p>הסיפורים האלה שקרו בגוגל ובמיקרוסופט כשרשתות נוירונים הצליחו תוך זמן מאוד קצר לגמד ולהפיל על מערכות מורכבות שהושקעו בהן עשרות שנות אדם של עבודה ואופטימיזציות ושיפורים, משקף תבנית שחזרה על עצמה שוב ושוב לאורך ההיסטוריה של ה-AI. יש מאמר שנכתב ב-2019 על ידי חוקר בשם ריץ' סאטון שקרא לזה "הלקח המר" (The Bitter Lesson). הוא הסביר שההנחה שהסתתרה מאחורי הרבה מהמחקר ב-AI ב-70 השנים האחרונות הייתה שכוח המחחשוב הזמין נשאר קבוע. אבל חוק מור המשיך לעבוד כל הזמן הזה ועל פני קווי זמן מספיק ארוכים כוח המחשוב הזמין גדל בצורה מאסיבית, וזה מגמד את השיפורים שאפשר להשיג על ידי זה שמקודדים יוריסטיקות וחוקים שנועדו לחקות מומחים אנושיים לתוך מערכות אוטומטיות.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">07:12</span>
                </div>
                <div class="content">
                    <p>במציאות שתי הגישות האלה סותרות אחת את השנייה. כשמתמקדים בגישה אחת נוטים להזניח את השנייה. אז גישת הידע האנושי כשמתמקדים בה, זה נוטה לסבך את השיטות באופן שעושה את זה מאוד קשה לשלב טכניקות כלליות ולעשות סקייל כשכוח המחשוב הזמין גדל. השיטות שניצחו את קספרוב, לפי מה שהוא הסביר, אלוף העולם בשחמט ב-97, התבססו על מחקר עמוק ומקיף. חוקרים שהתמקדו בשחמט וניסו לבנות מערכת מחשב שתבין את המבנה הייחודי של המשחק ותמנף את כל הידע האנושי סביבו, זלזלו בגישות פשטניות יותר שהתבססו על חומרה מאוד חזקה שאפשרה לבדוק את כל מרחב המהלכים האפשריים. אבל חוקרי השחמט התאכזבו כשהמערכת ברוט-פורס ניצחה בסוף כי זה לא בדיוק האופן שבו אנשים משחקים שחמט.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">08:06</span>
                </div>
                <div class="content">
                    <p>ואותו סיפור יחזור אחר כך עם המשחק גו 20 שנה אחרי זה. נגיע לזה בהמשך הפרק. מה שמבטא מצוין את הלקח המר בעיניי זה האופן המפורסם שבו סאטיה נאדלה הגיב כשהציגו לו בפעם הראשונה את היכולות של GPT. הוא פשוט קטע את ההדגמה בגסות ושאל איך זה ש-OpenAI הצליחו לעקוף את היכולות של פרויקט AI שעליו עובדים 1,500 חוקרים ב-Microsoft Research במשך עשורים. אם OpenAI בנו את זה עם 250 איש, למה בכלל יש לנו את Microsoft Research? ואפשר היה לשאול בדיוק את אותה שאלה גם אחרי החצי יום שג'פרי הינטון בילה במיקרוסופט ב-2009 בלכתוב קוד עם לי דנג.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">08:50</span>
                </div>
                <div class="content">
                    <p>המאמר של ריץ' סאטון מתאר את זה ככה: בהתחלה חוקרי AI מנסים לשלב ידע אנושי בתוך ה-agents שלהם. זה תמיד עוזר בטווח הקצר, משפר קצת את הביצועים וזה מאוד מתגמל בשביל החוקר. אבל בטווח הארוך זה נתקע באיזושהי תקרה וזה אפילו מונע התקדמות נוספת. בשלב מסוים פריצת הדרך האמיתית מגיעה על ידי גישה הפוכה של חיפוש ולמידת מכונה באמצעות הרבה יותר כוח מחשוב. ובסופו של דבר ההצלחה הזאת נגועה באיזושהי מרירות כי כוח המחשוב היה זה שניצח את הגישה שמשלבת מומחיות אנושית. אז משהו אחד שצריך ללמוד מהלקח המר הוא הכוח האדיר של טכניקות לשימוש כללי (General Purpose) שיכולות לעשות סקייל יחד עם כוח מחשוב חזק יותר בלי להיתקע בתקרה. שתי גישות כאלה הן Search ו-Machine Learning.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">10:11</span>
                </div>
                <div class="content">
                    <p>דמיס חסביס, הפאונדר והמנכ"ל של DeepMind שממשיך לנהל אותה בתוך גוגל עד היום, את דייוויד סילבר, אחד העובדים הראשונים בחברה, הוא פגש כבר בתור נער בטורניר שחמט באנגליה. חסביס נחשב אז לעילוי והוא זכה בכמה טורנירים של פנטמיינד - זה כמו אולימפיאדה רק למשחקים כמו שחמט ודמקה ושבץ נא. ולצד האובססיה למשחקים הייתה לחסביס גם אובססיה לבינה מלאכותית. החלום שלו היה לבנות מכונה שתוכל לחקות את המוח האנושי. התואר הראשון של חסביס היה במדעי המחשב ולימודי הדוקטורט שלו התמקדו במדעי המוח. את הפוסט-דוקטורט הוא התחיל במעבדה באוניברסיטת לונדון שממש ישבה בצומת שבין שני הדברים האלה, מדעי המוח ו-AI, והפרופסור שהקים אותה היה לא אחר מאשר ג'פרי הינטון.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">11:15</span>
                </div>
                <div class="content">
                    <p>במעבדה הזאת חסביס פגש את שיין לג, שעדיין עובד איתו ב-DeepMind היום, ואת מוסטפה סולימאן, שהיום הוא המנכ"ל של Microsoft AI. עם שני השותפים האלה הם הקימו ביחד את DeepMind ב-2010. השם של החברה משקף את השאיפה לשלב בין Deep Learning לבין המוח האנושי (Human Mind). המטרה המוצהרת איתה הם פתחו את התוכנית העסקית שלהם הייתה Artificial General Intelligence (בינה מלאכותית כללית - AGI). הם התחילו מלבנות תוכנה שתוכל לשחק משחקי מחשב קלאסיים משנות ה-80 כמו פונג או פולשים מהחלל או Breakout שובר קירות. אבל בניגוד לגישות שדגלו בלקודד יוריסטיקות וחוקים לתוך התוכנה, האלגוריתם של DeepMind פשוט למד איך לשחק במשחקים האלה בעצמו דרך ניסוי וטעייה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">12:15</span>
                </div>
                <div class="content">
                    <p>הטכניקה הזאת נקראת Reinforcement Learning. האלגוריתם מנסה כל מיני מהלכים, רואה מה התוצאה שלהם ואז בהתאם מעדכן את ההסתברות שהוא יבצע את אותו מהלך בפעם הבאה שהוא ייתקל במצב דומה. אחרי כמות מספיק גדולה של משחקים שהאלגוריתם משחק לבד, מגיעים לאלגוריתם עם משקלים עם הסתברויות שנלמדו בצורה אוטומטית. האלגוריתם למד בעצמו איך לשחק וזה רעיון שנועד לחקות את האופן שבו המוח של ילדים למשל לומד איך לשחק במשחקים האלה. במקרה של Breakout זה לקח למחשב בערך שעתיים כדי למצוא טריק שיאפשר לנצח את המשחק במהירות דרך זה שפותחים מעבר של כמה בלוקים שדרכה הכדור יכול לעבור אל מאחורי הבלוקים ואז הוא קופץ הלוך ושוב בין הקיר לבין הבלוקים ומוריד את כולם די מהר. המערכת הייתה מסוגלת לשחק ככה במהירות ודיוק גבוהים הרבה יותר מכל שחקן אנושי.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">13:30</span>
                </div>
                <div class="content">
                    <p>חסביס הצליח להשיג פגישה עם פיטר ת'יל, אחד המשקיעים הידועים בסיליקון ואלי ובעצמו חובב שחמט, שהשקיע ב-DeepMind 1.4 מיליון פאונד בסבב ה-seed שלהם. ופיטר ת'יל גם הכיר להם חבר נוסף מקהילת המיליארדרים בסיליקון ואלי, שהוא בעצמו מכיר עוד מהימים שלהם ביחד ב-Paypal, את אילון מאסק. בתור יועצים טכניים הם גייסו גם את ג'פרי הינטון ולצידו גם את יאן לקון, שגם היה חלק מהקבוצה הקטנה שהאמינה ברשתות נוירונים בשנות ה-80 וה-90, והיום לקון הוא מוביל את מחקר ה-AI בחברת מטא. זאת הייתה קהילה די קטנה של חוקרי רשתות נוירונים במהלך החורף AI הארוך, והיום הרבה מהם מובילים את תחום ה-AI בחברות הביג-טק או מנהלים בעצמם חברות בשווי של מיליארדי דולרים.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">14:12</span>
                </div>
                <div class="content">
                    <p>הסיפור כפי שהוא מסופר בספר Genius Makers הוא שאילון מאסק צפה בסרטון של DeepMind AI משחק באחד המשחקים האלה בזמן שהוא טס במטוס פרטי, ולארי פייג' גם היה על הטיסה הזאת. הוא שמע את השיחה של מאסק לגבי DeepMind וככה הוא למד על החברה החדשנית הזאת מלונדון. ופייג' החליט שגוגל חייבת לקנות אותם. למשימת השכנוע הוא גייס את ג'פרי הינטון שנקנה על ידי גוגל כבר ב-2012 והיה אחד המנטורים של DeepMind. חסביס העדיף להישאר עצמאי אבל הוא השתכנע שהחברה לא תהיה מסוגלת להתחרות מול ענקיות הטק על לשלם משכורות לחוקרי AI ועל לרכוש מעבדים גרפיים. את השיחות בנוגע לרכישה חסביס קיים אז עם ג'פרי הינטון וגם עם ג'ף דין, שהוא כנראה המהנדס הכי מוכשר ומוערך בהיסטוריה של גוגל, ובזמנו הוא ניהל את Google Brain, פרויקט הבינה המלאכותית של גוגל. חסביס השתכנע ובינואר 2014 הוכרז שגוגל רוכשת את DeepMind ב-650 מיליון דולר.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">15:24</span>
                </div>
                <div class="content">
                    <p>אפשר להגיד ש-DeepMind שילמה על הרכישה של עצמה כשהיא אימנה מערכת AI לניהול צריכת החשמל בדאטה סנטרס של גוגל. המערכת ניהלה את ההפעלה של מנגנוני קירור בצורה כל כך יעילה שהיא חסכה לגוגל מאות מיליוני דולרים. מעבר לניהול צריכת חשמל, גוגל שילבה Deep Learning בשורה ארוכה של מוצרים - מ-Photos דרך Gmail ואפילו באלגוריתם החיפוש. ב-2007 ג'פרי הינטון התארח בגוגל כדי להרצות על הדבר החדש הזה, על רשתות נוירונים, זה עוד הרבה לפני ש-Deep Learning התפוצץ ובטח לפני שגוגל קנתה את הסטארט-אפ שלו. והוא תיאר שם איך אלגוריתם כזה אולי יוכל להיות שימושי גם לחפש באוסף עצום של מסמכים. הוא אמר בצחוק שאם רק תהיה חברה שתהיה מוכנה לספק קצת כסף כדי שנוכל לבנות את זה. והחזון הזה הפך למציאות 8 שנים מאוחר יותר כשדווח ב-2015 שמערכת בשם RankBrain שמבוססת על רשת נוירונים אחראית כבר ל-15% מתוצאות החיפוש בגוגל ומשיגה תוצאות באיכות הרבה יותר גבוהה מהמערכות הוותיקות של החברה. זוכרים את הלקח המר שדיברנו עליו קודם? זה בא לידי ביטוי גם בסיפור הזה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">16:41</span>
                </div>
                <div class="content">
                    <p>השימוש הנרחב ב-AI הציב אתגר בצד התשתיות. ג'ף דין הבין שאם כל אחד ממיליארד הטלפונים שמריצים אנדרואיד ישתמש במערכת זיהוי הדיבור החדשה של גוגל רק במשך שלוש דקות ביום, זה כבר יספיק כדי שגוגל תהיה חייבת להכפיל את הדאטה סנטרס ותשתיות המחשוב שלה כדי להתמודד עם זה. "אנחנו פשוט נצטרך עוד גוגל", היה איך שהוא ניסח את זה, וזאת הייתה בעיה מאוד גדולה. זה הוביל בסופו של דבר לפתח שבב ייעודי, Tensor Processing Unit (TPU), שנועד להיות יעיל במיוחד כדי לעבד טנסורים - אלו האובייקטים המתמטיים ברשתות הנוירונים של גוגל. היכולות של המעבד הזה הן די מוגבלות יחסית ל-GPU של Nvidia, אבל את המשימות הספציפיות שהוא נועד לבצע ה-TPU יכול לעשות הרבה יותר מהר. מעבד הטנסור היה מה שאיפשר לצוות המחקר של גוגל למשל לעמוד במשימה שאפתנית שג'ף דין הציב בפניהם ב-2015 - לאמן על פני כל המידע באינטרנט מערכת שתוכל לתרגם בין שפות. ה-TPU הפחית את זמן התרגום של משפט בודד מ-10 שניות לכמה אלפיות שנייה. כמה חודשים מאוחר יותר כשהושקה גרסה של Google Translate שמתבססת על רשת נוירונים.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">18:12</span>
                </div>
                <div class="content">
                    <p>והיו גם המשחקים. ב-2017 DeepMind פירסמה מאמר שמתאר את AlphaZero, תוכנית מחשב שנועדה לשחק שחמט. תהליך האימון התבצע על מעבדי ה-TPU, והקלט היחיד היה חוקי משחק השחמט בלי טבלאות מצבים או יוריסטיקות או ספרים שנכתבו על המשחק. רק באמצעות טכניקה של Reinforcement Learning התוכנית למדה את האלגוריתם באמצעות זה שהיא שיחקה נגד עצמה עשרות מיליוני משחקים של שחמט. AlphaZero השיגה ביצועים עדיפים מול כל המנועים המובילים באותה תקופה והפכה לשחקן השחמט האוטומטי הכי טוב בעולם.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">18:42</span>
                </div>
                <div class="content">
                    <p>וזה המשיך מעבר לשחמט. בנסיעה למטה של גוגל ב-Mountain View אחרי הרכישה, דמיס חסביס גילה שהוא חולק תחום עניין משותף עם סרגיי ברין, הקו-פאונדר של גוגל, כי שניהם מאוד התלהבו מהמשחק גו. סרגיי סיפר שבזמן שהוא ופייג' בנו את גוגל בתור סטודנטים בסטנפורד, פייג' ממש דאג מכמה זמן השותף שלו מבלה בלשחק גו. וחסביס אמר שלדעתו הצוות שלו מסוגל לבנות מערכת שתנצח את אלוף העולם בגו. זאת הייתה הצהרה מאוד שאפתנית בגלל שגו זה משחק הרבה יותר מורכב משחמט. יש הרבה יותר מהלכים שכל שחקן יכול לבצע בכל תור, וכשזה גדל בצורה אקספוננציאלית על פני משחק שלם זה מוביל לזה שמספר המצבים האפשריים במשחק גדול יותר ממספר האטומים על פני כדור הארץ. אז בשביל לפתח אסטרטגיה צריך לנתח מרחב אפשרויות שהוא בסדרי גודל יותר עצום מאשר בשחמט.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">19:56</span>
                </div>
                <div class="content">
                    <p>את האופן שבו חסביס ניהל את פרויקט AlphaGo, ג'פרי הינטון השווה לאופן שבו אופנהיימר ניהל את ה-Manhattan Project, וזאת לא תהיה הפעם האחרונה שמשווים בין פיתוח של AI לפיתוח של נשק גרעיני בשנות ה-40. מעל 200 מיליון אנשים צפו בסדרת המשחקים של המערכת האוטומטית AlphaGo מול אלוף העולם לי סדולה שנערך בקוריאה במרץ 2016, ו-AlphaGo הצליחה לנצח בסדרה של חמישה משחקים באירוע שהביא לתודעה הציבורית את מהפכת ה-AI כי גו נחשב לפסגת האינטליגנציה האנושית ועכשיו המכונה התעלתה על המוח האנושי גם כאן. וחשוב לציין גם על התרומות האדירות של עוד מערכת מבית DeepMind בשם AlphaFold שהציגה ביצועים מרשימים בניתוח מבנה של חלבונים מורכבים. דמיס חסביס זכה בפרס נובל לכימיה לאחרונה יחד עם חוקר נוסף מ-DeepMind בשם ג'ון ג'מפר.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">21:10</span>
                </div>
                <div class="content">
                    <p>הניצחון של AlphaGo המחיש את העוצמה של הטכנולוגיה החדשה וגם את האפשרות שיום אחד היא תאפיל על האנושות. אבל היו בסיפור הזה כמה נקודות מעודדות בעיניי לגבי עתיד היצירתיות האנושית. אחת מהן הייתה במהלך המשחק הרביעי בסדרה. אחרי 77 מהלכים לי פשוט עצר ובהה בלוח במשך 20 דקות, ואחר כך הוא ביצע מהלך שגרם ל-AlphaGo להתבלבל. מהלך 78 של לי הוציא את AlphaGo מאיזון והתחזיות של האלגוריתם לגבי סיכויי הניצחון של עצמו במשחק התחילו לצנוח. אחרי עוד כמה שעות AlphaGo נכנעה, זה היה ההפסד היחיד שלה בסדרה. ואחר כך אחרי שהם בדקו את הלוגים, חסביס הסביר ש-AlphaGo פשוט לא צפתה את מהלך 78 של לי סדולה. האלגוריתם העריך את ההסתברות ששחקן גו אנושי אי פעם יבצע מהלך כזה בתור פחות מ-1 ל-10,000.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">22:24</span>
                </div>
                <div class="content">
                    <p>אז מסתבר שה-AI דחפה את אלוף העולם בגו להיות טוב יותר ויצירתי יותר ולנסות מהלכים חדשים שאף אחד לא ניסה אף פעם. ואולי יש כאן מסר מעודד לגבי ההשפעה של AI על היצירתיות האנושית באופן כללי, כי אולי היא תדחוף אותה לרמות חדשות. יש מאמר שהתפרסם כמה שנים מאוחר יותר שנפתח בציטוט של לי סדולה על זה שההפסד ל-AlphaGo גרם לו לרצות ללמוד את המשחק יותר לעומק. ובהמשך המאמר מראה שהיה זינוק במספר המהלכים המקוריים של שחקני גו אנושיים מאז סדרת המשחקים הזאת ב-2016. ויחד עם הזינוק ביצירתיות יש גם עלייה באיכות של האסטרטגיה שהם מפעילים. ואולי יהיה אפקט כזה גם בעוד תחומים, למרות שיש הרבה תחזיות קודרות ששומעים מהרבה אנשים על זה שהאינטליגנציה האנושית הולכת לאבד את הרלוונטיות שלה. אולי דווקא ההשפעה של AI תהיה לעורר השראה בקרב בני אנוש ולהוביל אותנו לפרוץ את גבולות היצירתיות האנושית בתחומים כמו מוזיקה או כתיבה או אמנות או עיצוב ואולי אפילו הנדסה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">23:49</span>
                </div>
                <div class="content">
                    <p>לא כולם היו מרוצים מהרכישה והסיסוג של DeepMind בתוך גוגל. למשל אילון מאסק שכתב בסוף 2014 ציטוט: "הסיכון שמשהו מאוד מסוכן הולך לקרות הוא במסגרת של 5 השנים הקרובות, 10 שנים לכל היותר. זה לא מקרה של לקרוא זאב על משהו שאני לא מבין בו, אני לא לבד במחשבה שאנחנו צריכים לדאוג. חברות ה-AI המובילות נקטו בצעדים נרחבים כדי לדאוג לבטיחות, הן מכירות בסכנה אבל מאמינות שהן יוכלו לעצב ולשלוט בסופר-אינטליגנציה דיגיטליות ולמנוע מהגרסאות הרעות לברוח אל האינטרנט. עוד נראה." סוף ציטוט.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">24:28</span>
                </div>
                <div class="content">
                    <p>בתור משקיע מוקדם ב-DeepMind, מאסק לא היה מרוצה מהמכירה לגוגל. הוא סיפר שלארי פייג' היה חבר קרוב שלו, אבל כמו שמאסק ניסח את זה: "לארי פייג' עלול לבנות משהו מרושע בלי להתכוון לזה". מאסק המשיך לדבר על הסכנות שבפיתוח AI ולנסות לשכנע חוקרים מובילים בתחום להצטרף אליו, מה שבסופו של דבר הוביל להכרזה המשותפת של אילון מאסק וסם אלטמן על הקמת OpenAI בדצמבר 2015. איליה סוצקבר שהסכים לעזוב את גוגל לטובת המיזם החדש מונה להוביל שם את המחקר, וגרג ברוקמן שהיה אז ה-CTO של Stripe עזב כדי להצטרף בתור ה-CTO של החברה החדשה. OpenAI הוצגה כחברה ללא מטרות רווח שנועדה להטיב עם כלל האנושות. אבל בן תומפסון היה כבר אז קצת סקפטי לגבי זה. הוא כתב כבר בהתחלה שזה לא ברור אם לקחת משהו שהוא כביכול כל כך מסוכן ולעשות אותו זמין ופתוח בצורה נרחבת ישפר את המצב או דווקא יחמיר את הבעיה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">25:39</span>
                </div>
                <div class="content">
                    <p>מצד שני כן אפשר לראות היגיון עסקי מאחורי המהלך הזה. לפייסבוק ולגוגל היה אז יתרון אדיר מבחינת גישה לטאלנט בתחום שכולו היה מועסק באחת משתי החברות האלה, וגם מבחינת כמויות הדאטה שהם אגרו. חברה שכביכול נועדה להיטיב עם האנושות תוכל לגייס חלק מהחוקרים המובילים ב-AI, כמו שOpenAI עשתה בהצלחה עם סוצקבר כבר מהיום הראשון, ולסגור חלק מהפער מול חברות הביג-טק. וזה יוכל לאזן את המשחק למשל בשביל טסלה, החברה של מאסק, או בשביל סטארט-אפים שיוצאים מ-Y Combinator, האקסלרטור המוביל שסם אלטמן ניהל בזמנו.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">26:24</span>
                </div>
                <div class="content">
                    <p>מה שהתברר די מהר היה שזה עולה הרבה מאוד כסף לבנות AGI, גם אם עושים את זה בשביל מטרה נעלה כמו להביא את הטכנולוגיה הזאת לכלל האנושות. הטאלנט שצריך בשביל לבנות את זה נדרש לוותר על משכורות מאוד מאוד גבוהות שהגיעו למשל במקרה של איליה סוצקבר למיליוני דולרים בשנה שגוגל הציעו לו כדי לא לעזוב לטובת OpenAI. וגם ה-GPUs של Nvidia עולים המון כסף, אי אפשר לממן את כל זה רק מתרומות לצדקה ולצפות להתחרות בגוגל ובפייסבוק. ועוד תובנה שסם אלטמן כנראה הגיע אליה, וכאן זו רק השערה שלי, אבל נראה שבניגוד לתוכנית המקורית לבנות AI פתוח ולחלוק אותו עם כל העולם כדי להיטיב עם סטארט-אפים בוגרי Y Combinator ככה שיהיה להם סיכוי להתחרות מול גוגל ופייסבוק, אני חושב שאלטמן בשלב מסוים פשוט הבין ש-OpenAI בעצמה הפכה להיות ההזדמנות לנצח את גוגל ופייסבוק, ועל הסיכוי הרבה יותר גבוה לעשות את זה מכל סטארט-אפ אחר שעבר ב-YC.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">27:42</span>
                </div>
                <div class="content">
                    <p>ב-2018 עדכנו את הצ'רטר של OpenAI. באופן אירוני החברה שנושאת את השם Open AI, AI פתוח, לפי הצ'רטר החדש הולכת להפסיק לשתף בפרטים אודות המחקר שלה. באותה שנה גם אילון מאסק עזב את הדירקטוריון של החברה וכדי לממן את הפיתוח וההתקדמות אלטמן הגיע להסכם עם סאטיה נאדלה מנכ"ל מיקרוסופט שתשקיע אז מיליארד דולר בחברה של אלטמן, שאותם OpenAI הולכת להוציא על תשתיות מחשוב בענן של מיקרוסופט. זה מה שהוביל למבנה מוזר שבו חברת OpenAI Non-profit שולטת בחברה בת OpenAI For-profit שגייסה כסף ממיקרוסופט. כתבתי בהרחבה על המבנה המוזר והבעייתיות סביבו אחרי ניסיון הפוטש בסם אלטמן בשנה שעברה, והייתה בדרך גם תביעת טרולינג שאילון מאסק הגיש כנגד החברה בגלל שינוי הכיוון שהיא לקחה. כתבתי על כל זה ויש לינקים במהדורה אז אני לא הולך להרחיב לגבי זה כאן.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">29:00</span>
                </div>
                <div class="content">
                    <p>הנקודה היא שגם עם המעבר ההדרגתי הזה מארגון צדקה ללא כוונת רווח לחברה שככל הנראה שואפת לעשות הרבה רווחים, לאורך כל שבע השנים הראשונות האלה של החברה שהוקמה כבר בסוף 2015, OpenAI נראתה יותר דומה למעבדת מחקר מאשר לכל דבר אחר. אבל זה השתנה כשהגיעה המפץ הגדול של נובמבר 2022. ולפני שנרחיב עליו ניקח כמה צעדים אחורה כדי להבין איך הוא הגיע.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">29:34</span>
                </div>
                <div class="content">
                    <p>איאן גודפלו חזר הלום שיכר לדירה שלו כשהרעיון הכה בו. הוא למד לתואר ראשון ושני תחת ההדרכה של אנדרו אן-ג'י בסטנפורד, שבעצמו אחד החוקרים המובילים בעולם ל-AI ומי שהתחיל את פרויקט המכונית האוטונומית של גוגל. ב-2014 כשגודפלו היה לקראת סוף לימודי הדוקטורט שלו באוניברסיטת מונטריאול, הייתה תחרות די חזקה לגייס אותו בין מעבדת המחקר של יאן לקון בפייסבוק לבין DeepMind של גוגל. גודפלו בחר את ההצעה של DeepMind והחברים שלו למעבדה באוניברסיטת מונטריאול ערכו לו אירוע פרידה בבר מקומי שאני לא יודע לבטא את השם שלו בצרפתית אבל התרגום הוא "שלושת המפלצות".</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">30:25</span>
                </div>
                <div class="content">
                    <p>אז בין כל הבירות שהם שתו שם הם התווכחו מה תהיה הדרך הנכונה לבנות מכונה שתייצר תמונות ריאליסטיות, למשל תמונות של חתול או כלב שירגישו אמיתיות אבל לגמרי יוצרו על ידי מחשב והחתולים או הכלבים האלה לא יהיו קיימים בעולם. לגודפלו היה כיוון מאוד שונה מהרעיונות שהיו לחברים שלו למעבדה. הם חשבו בעיקר על ניתוח סטטיסטי של תדירות של פיקסלים בתמונות, אבל הוא חשב על ממש לבנות רשת נוירונים שתלמד מרשת נוירונים אחרת. קצת כמו אלגוריתמים שמשחקים שח או גו אחד נגד השני, אז רשת נוירונים אחת תנסה לייצר תמונה ריאליסטית והרשת השנייה תנסה לזהות איפה התמונה היא לא אמיתית ולהצביע על הפגמים, ואחר כך בעקבות זה הרשת הראשונה תנסה לייצר עוד תמונה וכן הלאה. עם הדו-קרב הזה יימשך מספיק זמן, הרשת הראשונה אולי תוכל לייצר תמונות באיכות די גבוהה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">31:28</span>
                </div>
                <div class="content">
                    <p>הקולגות היו סקפטיים, אבל זה בדיוק מה שגודפלו ניגש לעבוד עליו כשהוא חזר הביתה. רק עם האור שריצד ממסך הלפטופ שלו, גודפלו שלא רצה להפריע לחברה שלו לישון, עדיין היה קצת מבוסם מהבירות והוא אימן שתי רשתות נוירונים. כמה שעות אחר כך זה עבד. התמונות היו קטנטנות וקצת מטושטשות אבל הן נראו אמיתיות. במאמר שהוא פירסם על הרעיון גודפלו קרא להם Generative Adversarial Networks או GANs בקיצור. ויאן לקון קרא ל-GANs הרעיון הכי מגניב ב-Deep Learning ב-20 השנים האחרונות. וזה הרעיון שגודפלו דחף קדימה כשהוא הצטרף ל-DeepMind בקיץ 2014. אבל רעיון אפילו יותר מגניב הגיע כמה שנים מאוחר יותר שכמו שהלקח המר מלמד טרף את כל הקלפים והאפיל על כל ההתקדמויות שהיו עד לאותו רגע.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">32:38</span>
                </div>
                <div class="content">
                    <p>זה היה בתקופה של ויכוח בקרב קהילת הבינה המלאכותית שלמרות ההישגים המדהימים בשורה של תחומים כמו Speech Recognition או Computer Vision או משחק גו או ניתוח של חלבונים, היו מבקרים שעדיין טענו שמדובר בסך הכל ב-Pattern Matching, בהתאמת של תבניות ולא בהבנה אמיתית. וזה היה אחד הנושאים בדיבייט שנערך בין יאן לקון לבין מדען בשם גארי מרקוס. לקראת הסוף של הדיבייט הייתה אישה שדיברה מהקהל והכריזה שבתחום הבנת השפה NLU לא הייתה שום התקדמות. וזה היה ב-2017. שנה מאוחר יותר ההתקדמות הגיעה בגדול כשגוגל פירסמה מערכת בשם BERT שהצליחה במשימות של השלמת משפטים ובפעם הראשונה קיבלה ציון דומה למשתתפים אנושיים.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">33:38</span>
                </div>
                <div class="content">
                    <p>המערכת התבססה על מה שהחוקרים כינו "מודל שפה אוניברסלי". לא מערכת נקודתית שנבנתה לטובת משימה או מבחן מסוים. כמו מערכות דומות שנבנו ב-OpenAI באותו זמן, מודל השפה האוניברסלי התבסס על כמות ענקית של דאטה שכללה בין היתר את כל הספרים שאי פעם נכתבו וכל המאמרים בוויקיפדיה. המשימה שהמערכת למדה היא לנחש את המילה הבאה במשפט, Generate Next Token. ומה איפשר את פריצת הדרך הזאת של מודל שפה אוניברסלי? אז ב-2017 הייתה קבוצת חוקרים מגוגל שפירסמו מאמר מכונן תחת הכותרת Attention Is All You Need. הם הציגו שם טכניקה בשם Transformer שאיפשרה להציג ביצועים בסדרי גודל יותר טובים מהטכניקות שהיו נפוצות בזמנו לעיבוד שפה. אם מותחים קווי דמיון בין המהפכה שאולי תצמח מ-Generative AI היום לבין המצאת המחשב האישי בשנות ה-70 וה-80, אז ההקבלה של הטרנספורמר זה כנראה המצאת הטרנזיסטור או המיקרו-פרוססור בזמנו. כתבתי על הטרנספורמר עוד בתחילת הדרך של הבלוג, אתם יכולים לחפש את מהדורה מספר 7 של הרהורי יום שישי.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">35:12</span>
                </div>
                <div class="content">
                    <p>וגוגל שיחררו ממש את כל הקוד של BERT ב-Open Source ואחר כך גם אימנו את המערכת על עוד 100 שפות נוספות. היו חברות אחרות שבנו מערכות אפילו יותר גדולות. OpenAI השיקו את הגרסה הראשונה של Generative Pre-trained Transformer או GPT-1 בקיצור ביוני 2018, את GPT-2 ב-2019 ואת GPT-3 ב-2020. כמות הפרמטרים גדלה בערך פי 100 בכל איטרציה כזאת, ורק בסדר גודל של GPT-3 שהגיעה כבר למאות מיליארדי פרמטרים, מודלי השפה הגדולים באמת התחילו להרשים עם יכולת לייצר טקסט שנראה קוהורנטי או תמונות שמרגישות אמיתיות באיכות גבוהה. אבל המפץ הגדול באמת הגיע קצת אחר כך בעוצמה שכנראה הפתיעה גם את מי שהיה מעורב בו.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">36:13</span>
                </div>
                <div class="content">
                    <p>ציטוט: "אימנו מודל שנקרא ChatGPT שמבצע אינטראקציה בצורה קונבנציונלית. פורמט הדיאלוג מאפשר ל-ChatGPT לענות על שאלות המשך, להודות בטעויות שלו, לאתגר הנחות שגויות ולדחות בקשות לא ראויות. אנחנו נרגשים להציג את ChatGPT כדי לקבל פידבק ממשתמשים וללמוד על החוזקות והחולשות שלו. במהלך תקופת המחקר השימוש ב-ChatGPT הוא חינם. נסו אותו עכשיו ב-chatgpt.com". סוף ציטוט. ההכרזה הקצרה הזאת של OpenAI בסוף נובמבר 2022 גרמה להכל להתפוצץ. בפינה שלי של העולם זה הרגיש כמו אירוע מאוד מכונן, עד כדי כך שהקדשתי מהדורה שלמה בניוזלטר שבדיוק התחלתי אז, הרהורי יום שישי כדי לדבר על זה. ועדיין לא הייתי מסוגל לנחש עד כמה תהיה גדולה ההשפעה של זה, אף אחד לא היה יכול.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">37:22</span>
                </div>
                <div class="content">
                    <p>עד אותו רגע OpenAI היו סטארט-אפ חם שלוקח הימור גדול על עתיד ה-AI. המודל העסקי הטבעי בשביל חברה כזאת שמוקדת במחקר היה API שעליו OpenAI גבתה כסף לפי שימוש. אבל תוך כמה שבועות ChatGPT, שהיה אמור להיות דמו למטרות מחקר ואולי קצת כדי לקדם את החברה ולמשוך אליה תשומת לב, צבר מעל 100 מיליון יוזרים - הצמיחה המהירה ביותר של אפליקציית קונסומר אי פעם. כמו שבן תומפסון תיאר את זה אז, מבלי להתכוון OpenAI הפכה מחברת מחקר ותשתיות לחברת קונסומר-טק. וזה דורש תרבות שונה לגמרי מתרבות של חברה שמוקדת במחקר. המתחים שזה יצר כנראה היו חלק ממה שהוביל לטלטלות שהגיעו לשיא בניסיון שנכשל לפטר את סם אלטמן לפני שנה ולגל העזיבות של הרבה בכירים לאחרונה, כולל סוצקבר וברוקמן שהיו חלק מצוות ההובלה המקורי של OpenAI. אבל שוב, היא הוקמה בתור מעבדת מחקר והנה סיפור שממחיש אולי את השינוי הגדול שהחברה עברה מאז.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">38:50</span>
                </div>
                <div class="content">
                    <p>בסוף 2023 היה כנס מפתחים של OpenAI. סאטיה נאדלה התארח על הבמה ב-DevDay לצד סם אלטמן שהכריז שם על שורה של השקות מאוד מלהיבות, בין היתר הושק שם המודל GPT-4 Turbo והכריזו על ירידה מאוד חדשה במחיר של השימוש בו באמצעות API. בן תומפסון הסביר בזמנו שזה תזמון טוב להכריז את זה בדיוק אחרי שסאטיה נאדלה הופיע על הבמה בגלל שחלק ממה שמאפשר את ההתייעלות והירידה במחיר זה העובדה שמיקרוסופט אז בנתה את כל אסטרטגיית ה-AI שלה סביב מודל ה-GPT של OpenAI, בניגוד לאמזון למשל שלקחה גישה מודולרית ופתוחה יותר והיא מארחת אוסף גדול של מודלים ב-AWS. נאדלה הסביר שזה שהם מתמקדים במודל אחד בודד מאפשר להם להוסיף אופטימיזציות לכל אורך הסטאק וככה OpenAI יכולה למכור את ה-API במחיר הרבה יותר נמוך מהמתחרות.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">40:08</span>
                </div>
                <div class="content">
                    <p>אבל שנה מאוחר יותר ה-DevDay של OpenAI נערך השנה בכלל בדלתיים סגורות, אנחנו לא יכולים לראות את ה-Keynote. וסאטיה נאדלה, אולי בתור לקח מהטלטלות וניסיון הפוטש שהיה ב-OpenAI בשנה שעברה, כבר לא שם את כל הביצים של מיקרוסופט בסל של OpenAI. בכנס המפתחים האחרון של מיקרוסופט הוא אפילו אמר שמודלי שפה גדולים הופכים לקומדיטי, הרבה מזה כנראה בזכות מטא והמודל Llama 3 שיצא ב-Open Source, דיברנו על זה בפרק הקודם. זה שינוי של 180 מעלות להגיד שמודלים הם קומדיטי לעומת הקו שנאדלה הציג רק לפני שנה כשהוא דיבר על היתרונות של מיקרוסופט מזה שיש לה גישה בלעדית למודלים המתקדמים של OpenAI.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">41:10</span>
                </div>
                <div class="content">
                    <p>משהו שממחיש את זה אולי העובדה שמיקרוסופט השבוע הכריזו שהם הולכים לאפשר להשתמש במודלים נוספים במוצר ה-Copilot שלהם, כולל המודלים של Anthropic וגוגל. העובדה שהמודלים עצמם הופכים לקומדיטי זה כנראה חלק ממה שדחף את OpenAI ללכת All-in על ChatGPT. יש להם הזדמנות מעניינית סביב זה לאור המותג שכבר הולך ונבנה בתודעת הצרכנים - בעיניי הרבה מאוד אנשים ChatGPT זה מה שהם מקושרים למהפכת ה-AI. חברת קונסומר-טק זו אולי תוצאה רחוקה מאוד מהתוכנית המקורית שהייתה לסם אלטמן ואילון מאסק כשהם הקימו את OpenAI וכשהחברה יצאה לדרך, אבל אולי כמו מהלך 77 במשחק של AlphaGo, זה אולי עוד מקרה שבו AI מוביל אנשים למהלכים יצירתיים שמפתיעים אפילו את עצמם.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">42:11</span>
                </div>
                <div class="content">
                    <p>ציטוט: "אנחנו מתקדמים במשימה שלנו להבטיח את היתרונות של AGI לכלל האנושות. בכל שבוע מעל 250 מיליון אנשים מרחבי העולם משתמשים ב-ChatGPT כדי לשפר את העבודה, היצירתיות והלמידה שלהם. גייסנו 6.6 מיליארד דולר במימון חדש לפי שווי של 157 מיליארד דולר אחרי הכסף כדי להאיץ את ההתקדמות במשימה שלנו". סוף ציטוט. 157 מיליארד דולר זו הערכת שווי מאוד מאוד גבוהה. דיברנו בפרק 26 על בועות פיננסיות בתקופות של מהפכות טכנולוגיות, והערכת שווי שמשקפת מכפיל 40 על ההכנסות של חברה שלפי הדיווחים צפויה להשיג השנה 3.7 מיליארד דולר של הכנסות ולרשום הפסד של 5 מיליארד דולר בהחלט יכול להיות סימן לבועה שאולי מתפתחת סביב AI, כמו שדיברנו בפרק 27. אבל זאת כנראה לא בדיוק הדרך הנכונה להסתכל ספציפית על המקרה הזה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">43:38</span>
                </div>
                <div class="content">
                    <p>בדיווח שהתפרסם בניו-יורק טיימס היה גם תחזית הכנסות של 100 מיליארד דולר ב-2029, למרות שמי יכול לדעת מה יקרה עד אז. בראד גרסטנר, שקרן אלטימיטר שהוא מנהל השתתפה בסבב ההשקעה, הצדיק את השווי הגבוה עם שקף שמראה שהצמיחה בהכנסות של OpenAI מהירה אפילו יותר מתחילת הדרך של גוגל ופייסבוק. נקודת הפתיחה שהוא השתמש בה בשביל OpenAI הייתה ב-2022 כש-ChatGPT הושק, למרות שהחברה עצמה הוקמה כבר ב-2015 וזה כנראה עוד סימן לטרנספורמציה הגדולה שהחברה עברה מחברת מחקר לחברת קונסומר-טק. ולמרות כמה הבדלים בין OpenAI לגוגל ופייסבוק כמו העובדה שהם בתחילת הדרך היו רווחיות בשלב הרבה יותר מוקדם בעוד שOpenAI עדיין רושמת הפסדים עצומים של מיליארדים, ההשוואה הזאת ממחישה מה תזת ההשקעה כאן. במצבים הסתברותיים הגישה היא לפעמים להסתכל על תוחלת. מכפילים את ההסתברות לכל תרחיש בערך שלו וסוכמים את הכל. אז בהטלת קובייה למשל התוחלת של המספר שיתקבל מחושבת לפי שישית כפול 1 ועוד שישית כפול 2 וכן הלאה עד 6. ואם נעשה את החישוב הזה נקבל שבתוחלת הערך הצפוי של הטלת קובייה הוא 3.5.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">45:18</span>
                </div>
                <div class="content">
                    <p>במקרה של OpenAI התרחיש האופטימי הוא להיות חברה גדולה כמו גוגל ופייסבוק בשווי של טריליוני דולרים. גם אם מאמינים שיש רק 5% סיכויי הצלחה לתרחיש כזה ו-95% סיכוי שהחברה לא תהיה שווה כלום בסוף, 5% סיכוי לתרחיש של 3 טריליון דולר נותן 150 מיליארד דולר בתוחלת. ומה אם אתם מאמינים שיש אפילו 7% סיכוי שהם יצליחו או 10%? זה כבר יכול לגרום לשווי הזה להיראות לכם כמו דיל טוב. כדאי רק להיזהר כשעושים הערכות שווי בסגנון הזה כי במקרה הטוב אתם תפסידו את הכסף שלכם רק ב-9 מתוך 10 מקרים. התחזית של OpenAI היא לשיעור הכנסות של קרוב ל-12 מיליארד דולר בשנה הבאה. הצמיחה ההיפר-מהירה הזאת מביאה את השווי הנוכחי למכפיל 13 על ההכנסות של 2025. זה גבוה אבל לא רחוק ממה שהמניה של פייסבוק למשל קיבלה בזמן ההנפקה. אז אולי זה לא מופרז. השאלה הגדולה היא האם ההצלחה של ChatGPT שכבר עכשיו מייצרת את רוב ההכנסות של החברה, יותר מהשימוש ב-API, הולכת להיות בקנה מידה של פייסבוק.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">46:52</span>
                </div>
                <div class="content">
                    <p>פול גרהם, המקימים של Y Combinator ומי שהיה המנטור של סם אלטמן, פירסם מאמר ב-2012 תחת הכותרת "רעיונות סטארט-אפ שאפתניים באופן מפחיד". הרעיון השאפתני באופן מפחיד הראשון שהוא תיאר שם היה מנוע חיפוש שיתחרה בגוגל. בתחתית המאמר הייתה רשימת תודות לאנשים שקראו את הטיוטה והעירו הערות, והשם הראשון שמוזכר שם הוא סם אלטמן. ואם נשפוט על פי ההכרזה משבוע שעבר, סם אלטמן אכן קרא ביסודיות את המאמר. ציטוט: "ההכרזה על ChatGPT Search. עכשיו ChatGPT יכול לחפש באינטרנט באופן הרבה יותר טוב מבעבר. אתם יכולים לקבל תשובות מהירות ועדכניות עם לינקים למקורות רלוונטיים. זה משלב את היתרונות של ממשק שפה טבעית עם הערך של ציטוטי מניות, תוצאות ספורט, חדשות עדכניות ועוד".</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">47:54</span>
                </div>
                <div class="content">
                    <p>תכף אנחנו נדבר על ההכרזה הזאת ביחס לגוגל. חוויית החיפוש מבית OpenAI מזכירה עוד חברה שטוענת לכתר ה-disruption לגוגל שגם היא לפי הדיווחים מגייסת עכשיו סבב השקעה חדש, Perplexity AI. הם התחילו מראש עם מנוע תשובות שמתבסס על מודלי שפה גדולים ו-Perplexity צבר פופולריות מאוד מהר. הפאונדר ארווינד סריניוואס עבד בעבר גם ב-DeepMind וגם ב-OpenAI. אני כתבתי לו מזמן בטוויטר שאני באופן אישי לא מצליח להתרשם מהם, אבל אי אפשר להתעלם מהצמיחה המהירה שהם משיגים שהכפילה את קצב ההכנסות השנתי פי 5 ל-50 מיליון דולר. האם זה מצדיק הערכת שווי של 8-9 מיליארד דולר ש-Perplexity מבקשת בסבב הנוכחי לפי הדיווחים? אז לפי אותו היגיון שמאחורי השווי של OpenAI אפשר לקחת את השווי של גוגל היום כפול הסיכוי ש-Perplexity תהיה זאת שתדיח אותה. או שאפשר להשתמש ב-OpenAI בתור הקומפרבל.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">49:21</span>
                </div>
                <div class="content">
                    <p>העניין הבעייתי פה זה שזה מסוג הדברים שמביא בסופו של דבר לבועות להיווצר, כי ההסתברות שחברה אחת תדיח את גוגל היא לא בלתי תלויה בסיכוי של החברות האחרות לעשות את זה. Search עד עכשיו לפחות התברר כעסק של Winner Takes All. ואם Perplexity תהיה זאת שתדיח את גוגל, אז כנראה שOpenAI לא תעשה את זה. אז הנה תרחיש שבו המשקיעים של OpenAI עלולים להפסיד גם אם גוגל תודח מהפסגה בסופו של דבר. אבל האם זה יקרה בכלל?</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">50:07</span>
                </div>
                <div class="content">
                    <p>קצת אחרי ההשקה של ChatGPT סם אלטמן אמר בריאיון לבן תומפסון שאם הוא היה מנהל מונופול שבע ועצלן בתחום החיפוש, הוא היה מתחיל להיות מודאג. וגוגל לפי הפרסומים באמת הייתה מודאגת בסוף 2022. החברה שממנה בכלל יצאו פריצות הדרך שאיפשרו את כל זה ובראשן הטרנספורמר, דגרה על ה-LLMs שלה ואיפשרה ל-OpenAI להיות זאת שכובשת את העולם בסערה. זה הוביל להכרזה על קוד ילו בתוך גוגל לפי הדיווחים וצוותים שעובדים סביב השעון כדי להשיק את בארד שבהמשך כונה ג'מיני. היו כמה תקלות מביכות לאורך הדרך אבל אלה דברים שנוטים להישכח די מהר.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">50:56</span>
                </div>
                <div class="content">
                    <p>השאלה המרתקת היא האם גוגל תעבור Disruption והאם מנוע החיפוש יאבד את הדומיננטיות שלו לטובת משהו כמו ChatGPT. דיברנו על זה קצת בפרק 18 ודיברנו פה בהרבה פרקים על ההבדלים בין Sustaining Innovation לבין Disruptive Innovation ועל זה שגוגל משלבת תשובות מג'מיני בתוצאות החיפוש, הם קראו לזה AI Overviews, וזה משהו שזמין כבר לכלל המשתמשים בארצות הברית. בניגוד למאזין הממוצע של אופטיקאסט, רוב האנשים בעולם הם לא כאלה סקרנים והרפתקנים והם לא משתמשים הרבה בכלי ה-AI החדשים עדיין. אז אם החוויה שהם יקבלו מגוגל תהיה Good Enough, הם אולי אף פעם לא יגיעו לנסות אותם. היה צריך לבנות כאן חוויה שהיא תהיה פי 10 יותר טובה מגוגל ושלגוגל יהיה קשה להעתיק אותה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">52:13</span>
                </div>
                <div class="content">
                    <p>דיברנו בפרק 18 על מה שקרה בזמן המעבר למובייל וסיפרתי שהייתה VP שניהלה את הפרויקט של ה-Knowledge Panels ואמרה לנו שלמזלה היא לא צריכה לדאוג מאיך גוגל תעשה כסף, היא רק צריכה לדאוג לבנות את ה-Knowledge Cards האלה באופן שיהיה הכי שימושי ליוזרים. ונזכרתי בסיפור הזה כשקראתי את ההכרזה של גוגל האחרונה על זה שהצוות של ג'מיני עובר להיות כפוף ישירות לדמיס חסביס בתור חלק מ-DeepMind, לא בתור חלק מ-Search. וזה סימן שכנראה גם הם עכשיו לא צריכים לדאוג מההכנסות שגוגל עושה מחיפוש ואולי זה אומר שיש להם צ'רטר להתחרות בצורה ישירה בחברות כמו OpenAI ו-Perplexity באופן שמשחרר אותם מהאפקט של ה-Innovator's Dilemma. אם עשו את זה שם נכון, אז אולי גם אמרו להם משפט כמו: המשימה שלכם היא לבנות משהו יותר טוב שיגרום לחיפוש של גוגל לפשוט רגל.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">53:30</span>
                </div>
                <div class="content">
                    <p>אז אם לשפוט לפי התוצאות שגוגל דיווחו בשבוע שעבר, הדיסראפשן הזה גם עדיין לא נראה באופק, לפחות בינתיים. סדקים בהכנסות מחיפוש זה משהו שאנליסטים מחפשים בכל ריבעון מאז ההשקה של ChatGPT, אבל גם שנתיים אחרי זה ההכנסות האלה של גוגל עדיין צומחות בקצב דו-ספרתי ושולי הרווח שלהם מתרחבים. גוגל דיווחו שהעלויות של AI Overviews צנחו כבר ביותר מ-90% ושהפרסומות שהם מתחילים להציג לצד זה משיגות ביצועים טובים. וזה נכון שדיסראפשן יכול לקחת הרבה זמן וששנתיים זה פרק זמן יחסית קצר שאולי לא מספיק לאפקט של זה להיווצר. ChatGPT צומח מאוד מהר והופך למותג שמקושר בתודעה של הרבה משתמשים עם AI וחדשנות. אז אולי יש שם פוטנציאל אמיתי לדיסראפשן שבסוף כן יקרה. מצד שני גם מוצרים כמו Yahoo או America Online או Netscape נהנו מתודעת צרכנים די חזקה בסוף שנות ה-90. אבל למרות שהחברות האלה נהנו מכמויות אדירות של משתמשים וצמיחה מהירה ופרסום נרחב, הן לא שרדו הלאה לשלב האינטגרציה של ה-web.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">55:04</span>
                </div>
                <div class="content">
                    <p>ל-Netscape אפשר למתוח פה לא מעט קווי דמיון. דיברנו על זה שבזמן שביל גייטס עוד היה עסוק בחזון ה-Information Super Highway והניסיון לבנות מערכת הפעלה אינטראקטיבית לטלוויזיה בכבלים, הבראוזר שמארק אנדריסן בנה הופיע משום מקום והיה זה שהביא את ה-World Wide Web אל ההמונים. וזה קצת מזכיר את גוגל בזמן ש-ChatGPT הופיע. בזמנו ביל גייטס הצליח להתעשת בזמן ולבנות את Internet Explorer שימנף את יתרונות הדיסטריביוציה של מיקרוסופט ו-Windows כדי לרסק את Netscape. אז האם עכשיו כשגוגל נכנסים לזירה ברצינות, ג'מיני יהיה המקבילה של Internet Explorer? מצד שני בגזרת ה-Little Tech, הסטארט-אפים בסיליקון ואלי למדו כמה לקחים מאז 1997. או שאולי יהיה פה בכלל עוד סיפור בסגנון ה-Bitter Lesson, תגיע עוד פריצת דרך מפתיעה שתגמד את הביצועים של ה-LLMs והטרנספורמרים ותטרוף מחדש את כל הקלפים. אולי יופיע עוד משהו שיגרום גם ל-ChatGPT וגם לג'מיני לאבד את הרלוונטיות שלהם לטובה דברים חדשים שרובנו עדיין אפילו לא מדמיינים, כמו מהלך 77 של לי סדולה מול AlphaGo.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-אבי נתן זינגר type-content">
                <div class="paragraph-meta">
                    <span class="speaker-name">אבי נתן זינגר</span>
                    <span class="timestamp">56:32</span>
                </div>
                <div class="content">
                    <p>עד כאן להפעם, נמשיך בשבוע הבא.</p>
                </div>
            </article>
            
        
    </div>

    <script>
        const audio = document.getElementById('audio-player');
        function seekTo(time) {
            audio.currentTime = time;
            audio.play();
        }
    </script>

        </main>

        <footer>
            <p>&copy;  כל הזכויות שמורות לבעלי הפודקאסט. שירות זה מתמלל לכבדי שמיעה ואינו בעל הזכויות על התוכן.</p>
        </footer>
    </div>
</body>
</html>