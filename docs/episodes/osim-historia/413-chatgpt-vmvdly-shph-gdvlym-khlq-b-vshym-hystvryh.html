<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>413: ChatGPT ומודלי שפה גדולים, חלק ב' [עושים היסטוריה] - פודטקסט</title>
    <link rel="stylesheet" href="../../styles.css">
    <script defer src="../../search.js"></script>
</head>
<body>
    <div class="container">
        <header class="site-header">
            <div class="logo">
                <a href="../../index.html">פודטקסט</a>
            </div>
            
            <div class="search-box">
                <input type="text" id="search-input" placeholder="חיפוש...">
                <div id="search-results" class="search-results hidden"></div>
            </div>

            <nav class="main-nav">
                <a href="../../index.html" class="nav-link">פרקים אחרונים</a>
                <a href="../../podcasts.html" class="nav-link">כל הפודקאסטים</a>
                <a href="../../rss.xml" class="rss-link" title="RSS">
                    <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg>
                </a>
            </nav>
        </header>

        <main>
            
    <div class="episode-header">
        <h1>413: ChatGPT ומודלי שפה גדולים, חלק ב' [עושים היסטוריה]</h1>
        <div class="meta-row">
            <span class="meta-date">פורסם ב: 26 בנובמבר 2023</span>
            <a href="../../podcasts/osim-historia.html" class="meta-feed">עושים היסטוריה</a>
        </div>
    </div>

    <div class="transcript-container" id="transcript">
        
            <article class="paragraph speaker-Intro Speaker">
                <div class="paragraph-meta">
                    <span class="speaker-name">Intro Speaker</span>
                    <span class="timestamp">00:00</span>
                </div>
                <div class="content">
                    <p>אתם אוהבים חידות? לא כאלה של מה ההבדל בין חלב, אלא חידות שגורמות לכם לבהות בתקרה ולמלמל 'רגע, אבל אם הוא עשה ככה...' תקשיבו לזה: יש עשרה חדרים, בכל אחד מהם ישן שובב. באמצע הלילה, כל אחד מהשובבים בתורו מתעורר ובודק את הדלת של החדר שלו. אם הדלת שלו בסדר, היא שם, היא דלת, אז הוא הולך לדלת של אחד החדרים האחרים, לא החדר שלו, מפרק אותה וסוחב אותה למחסן, ואז חוזר לישון. אם הוא מתעורר ומגלה שאין לו דלת בחדר כי מישהו לקח אותה, אז הוא הולך למחסן, לוקח דלת, מתקין אותה בחדר שלו וחוזר לישון. ככה זה נמשך עד שכל אחד מעשרת השובבים התעורר ועשה את מה שהוא עשה. אנחנו לא יודעים באיזה סדר הם התעוררו, אנחנו לא יודעים איזה דלת כל אחד מהם פירק. השאלה היא: בסוף הלילה הזה, מה המספר המקסימלי של דלתות שיכולות להיות במחסן?</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Intro Speaker">
                <div class="paragraph-meta">
                    <span class="speaker-name">Intro Speaker</span>
                    <span class="timestamp">01:12</span>
                </div>
                <div class="content">
                    <p>אם בשלב הזה עצרתם רגע, או עשיתם פאוז, או העברתם אחורה כדי לשמוע את זה שוב, או התחלתם לספור על האצבעות או לצייר משהו על נייר, או לעצום עיניים ולהתרכז ממש - יופי, כי הפרסומת הזאת נועדה לכם. כי חידות כאלה, שהן חצי משחק וחצי כאב ראש, זה בדיוק סוג החשיבה של אנשים שנהנים לאתגר את המוח שלהם עם שאלות קשות. ואם זה אתם, אז כדאי שתדעו את הדבר הבא: במהלך חודש פברואר מתקיים השלב הראשון של המיונים לנבחרות ישראל במדעים.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Intro Speaker">
                <div class="paragraph-meta">
                    <span class="speaker-name">Intro Speaker</span>
                    <span class="timestamp">01:52</span>
                </div>
                <div class="content">
                    <p>יש דבר כזה: למדינת ישראל יש נבחרות בוגרות שהן מתחרות באולימפיאדות הבינלאומיות בכימיה, בפיזיקה, במתמטיקה, בביולוגיה, במדעי המחשב, בסייבר ובבינה מלאכותית. אליהן יכולים להתמיין תלמידות ותלמידים מכיתה ט' עד י"א. וישנה גם הנבחרת הצעירה שהיא עתודה לנבחרות הבוגרות, אליה מצטרפים כבר בכיתה ז'. אז מה עושים כשפרסומת כזאת נגמרת? פשוט נכנסים לרשת, מחפשים 'נבחרות ישראל במדעים', בודקים מתי זה קורה, ואולי מייצגים את ישראל באולימפיאדות הבינלאומיות במדעים. ואפילו לא צריך לדעת לעשות סקיפ בשביל זה. נבחרות ישראל במדעים הן מיזם משותף של משרד החינוך ומרכז מדעני העתיד של קרן מיימונידיס.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">02:32</span>
                </div>
                <div class="content">
                    <p>שלום וברוכים הבאים לעושים היסטוריה. פרק 413: צ'אט GPT ומודלי שפה גדולים, חלק ב'. כשייצא לאקרנים הסרט '2001: אודסיאה בחלל' ב-1968, התגובות הראשוניות של הקהל והמבקרים היו פושרות למדי. במאי הסרט סטנלי קובריק נחשב כבר אז לבמאי מוערך בזכות שוברי קופות כדוגמת 'ספרטקוס' ו'דוקטור סטריינג'לאב', אבל '2001 אודסיאה בחלל' היה אגוז קשה לפיצוח. העלילה הבלתי שגרתית השתרעה מהעבר הפרהיסטורי ועד העתיד הרחוק, ובמיוחד התקשה הקהל להבין את סוף הסרט שהיה בגדול סדרה של סצנות פסיכדליות חסרות פשר. בהקרנת הבכורה בניו יורק עזבו מאות צופים את הסרט באמצע.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">04:26</span>
                </div>
                <div class="content">
                    <p>עם השנים, עם זאת, תפס '2001 אודסיאה בחלל' מקום של כבוד בהיכל התהילה של ז'אנר המדע הבדיוני, והיום הוא נחשב לקלאסיקה בזכות האופן האמין והמציאותי יחסית שבו מתוארים מסעות בחלל - עניין לא מובן מאליו בשנות ה-60 - ובעיקר בזכות דמות יוצאת דופן שנחשבת לאחת הנבלים הזכורים ביותר בתולדות הקולנוע: המחשב HAL 9000, שהמצלמה האדומה דמוית העין שלו הפכה לייצוג אייקוני של בינה מלאכותית זדונית.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">05:01</span>
                </div>
                <div class="content">
                    <p>לפני שנמשיך, הנה תקציר זריז של עלילת הסרט. וכן, מותר לעשות ספוילר לסרט שיצא לאור לפני שהמציאו את המילה ספוילר. תגידו תודה שאני לא מספר לכם איך קוראים לאבא של לוק סקייווקר. במרכז עלילת הסרט נמצאת החללית 'דיסקברי 1' שעושה את דרכה אל כוכב הלכת צדק. מטרתה המוצהרת של המשימה היא חקר מערכת השמש החיצונית, אבל המטרה האמיתית היא לחקור את טבעו של עצם חייזרי בשם 'המונולית' - מלבן שחור וגדול שהתגלה על אדמת הירח ושולח שדרים מסתוריים לכיוון כוכב הלכת הגדול.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">05:46</span>
                </div>
                <div class="content">
                    <p>האל 9000 הוא הבינה המלאכותית שמנהלת את החללית לאורך המסע. אבל משלב מסוים האל מתחרפן והורג את אחד מאנשי הצוות. האסטרונאוט השני מצליח לגבור עליו ולכבות אותו ברגע האחרון. אחת התעלומות שהעסיקו את המעריצים האובססיביים מאז שיצא לאור הסרט היא השאלה: מה גרם להאל 9000 להשתגע ולנסות לחסל את אנשי הצוות שעל שלומם הופקד? עלילת הסרט לא מספקת תשובה ישירה לשאלה הזו, והאפשרות הפשוטה ביותר מן הסתם היא תקלה טכנית אקראית. אבל זו תשובה שלא עולה בקנה אחד עם אישיותו וסגנונו האמנותי של סטנלי קובריק שסרטיו תמיד היו עשירים ברבדים עמוקים וחבויים. ברור למדי שהבמאי המבריק ביקש להעביר לנו מסר שונה ומתוחכם יותר.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">06:44</span>
                </div>
                <div class="content">
                    <p>מיד נחזור אל '2001 אודסיאה בחלל' וננסה להבין מה גרם להאל 9000 לאבד את שפיותו, אבל ראשית קפיצה מהירה אל העתיד - זאת אומרת, אל ההווה. בפרק הקודם סיפרתי לכם על החרדה שאחזה בחלק מחוקרי הבינה המלאכותית בעקבות הצלחתם המפתיעה של מודלי שפה גדולים כדוגמת GPT-3 ו-GPT-4, הטכנולוגיה שמאחורי צ'אט GPT. וכשאני אומר 'חלק מחוקרי הבינה המלאכותית', אני לא מתכוון למיעוט קיצוני וקולני שמורכב מטיפוסים רואי שחורות שכותם אפשר למצוא בכל תחום של עשייה אנושית.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">07:51</span>
                </div>
                <div class="content">
                    <p>קחו לדוגמה את ההצהרה שפרסם במאי 2023 ארגון ללא מטרות רווח בשם 'המרכז לבטיחות בבינה מלאכותית'. ציטוט: 'מניעת הסיכון להכחדת המין האנושי על ידי הבינה המלאכותית צריכה להיות בעדיפות גלובלית עליונה, לצד סיכונים דומים בקנה מידה של ציוויליזציה כדוגמת מגפות או מלחמה גרעינית'. סוף ציטוט. בין 350 האישים שחתומים על ההצהרה הזו אפשר למצוא כמה מהשמות המפורסמים ביותר בעולם הטכנולוגיה, כדוגמת ביל גייטס, ריי קורצווייל, פיטר נורביג, מרטין הלמן ואפילו יוסי מטיאס, מנכ"ל גוגל ישראל. אנשים שאי אפשר לפקפק במידת ההבנה שלהם לגבי מחשבים.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">08:31</span>
                </div>
                <div class="content">
                    <p>יותר מכך, על ההצהרה הזו חתומים גם כמה מהאנשים שהיו מעורבים באופן העמוק ביותר בפיתוחם של מודלי השפה הגדולים: ג'פרי הינטון ויהושע בנג'יו, מי שנחשבים לאבות המייסדים של הבינה המלאכותית המודרנית; סם אלטמן, מנכ"לה של OpenAI; ואפילו איליה סוצקבר עצמו, המדען שפיתח את GPT-3. כשאנשים בסדר גודל של החבורה הזו מחווים דעה על משהו שקשור בבינה מלאכותית, זה כמו שסטיב ג'ובס ידבר על האייפון או שסטיבן קינג ייתן עצה בנושא כתיבה של ספרי אימה. כדאי להקשיב להם.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">09:08</span>
                </div>
                <div class="content">
                    <p>ברור מאליו שכמו כל טכנולוגיה חדשנית לכל אורך ההיסטוריה, גם צ'אט GPT ודומיו עתידים לחולל זעזועים ואולי אפילו זעזועים משמעותיים בעולמנו. אין ספור מילים נכתבו ונאמרו אודות האפשרות שמאות מיליוני עובדים יאבדו את משרותיהם לטובת כלי בינה מלאכותית, על החשש מפני כמויות אינסופיות של פייק ניוז שיציפו את הרשת, על תוכנות זדוניות מתוחכמות שיערערו את חיינו וכן הלאה וכן הלאה. אלו חששות לגיטימיים וסביר להניח שחלקם אפילו יתממשו בעתיד הקרוב במידה כזו או אחרת. אבל לא מפני האיומים האלה מזהירים המומחים שחתמו על ההצהרה שקראתי. האיום שהם מכוונים אליו הוא הרבה הרבה יותר משמעותי ומסוכן. איום שעשוי להביא, כלשונה של ההצהרה, לא פחות מאשר להכחדתו של המין האנושי. שמו של האיום הזה הוא 'בינה מלאכותית כללית' - Artificial General Intelligence, או בקיצור AGI.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">10:23</span>
                </div>
                <div class="content">
                    <p>מהי בינה מלאכותית כללית? כמו פורנוגרפיה ותודעה, בינה מלאכותית כללית היא מסוג הדברים שקשה מאוד להגדיר בצורה מדויקת. מקובל להשוות אותה לבינה שלנו, הבינה האנושית. כזו שמסוגלת לעמוד במגוון רחב של אתגרים ומשימות, ללמוד כישורים חדשים ולהסתגל למצבים משתנים. האל 9000 הוא ייצוג קלאסי של בינה מלאכותית כללית. הוא מסוגל לשוחח עם אסטרונאוטים בשפה אנושית טבעית וקולחת, לשחק איתם שחמט, לתפעל את החללית ולנווט אותה ליעדה ולבצע עוד מגוון של משימות שונות ומשונות. צ'אט GPT שלנו, לשם ההשוואה, הוא בינה מלאכותית צרה. הוא אמנם מסוגל לשוחח איתנו באופן אינטליגנטי, אבל הוא לא מסוגל לתפעל חללית או אפילו לנהוג במכונית אוטונומית.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">11:15</span>
                </div>
                <div class="content">
                    <p>קשה להפריז בפוטנציאל שגלום בבינה מלאכותית כללית לשנות את עולמנו. דמיינו לעצמכם רופא עם ידע אינסופי ומומחיות בכל ענף רפואי, שהוא גם מדען שיכול לנסח מאות תאוריות מדעיות חדשות בכל יום ולהגות ניסויים מבריקים כדי להוכיח או להפריך אותן. דמיינו ראש ממשלה שיש לו גישה מיידית ויכולת ניתוח של הנתונים הסטטיסטיים והתהליכים שמתרחשים במדינה, שהוא גם היסטוריון בעל הבנה מעמיקה בהיסטוריה האנושית וביתרונותיהן וחסרונותיהן של צורות השלטון השונות.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">11:54</span>
                </div>
                <div class="content">
                    <p>יש קונצנזוס מוחלט בקרב חוקרי הבינה המלאכותית שבינה מלאכותית כללית עשויה להיות הדבר הטוב ביותר שקרה לאנושות מאז שהבנו איך לשלוט על האש. היא עשויה לקדם את המדע והטכנולוגיה בקפיצות אדירות, לפתור לנו בעיות קשות כמו התחממות גלובלית ומסע בין כוכבי ולשפר את חייהם של כל בני האדם בכדור הארץ. אין פלא אם כן שמאז שהופיעו המחשבים הראשונים בשנות ה-40 של המאה הקודמת, חולמים מדעני המחשב על פיתוחה של טכנולוגיה שכזו. לרוע המזל, ההתקדמות המעשית שנרשמה ב-80 השנים האחרונות לקראת המטרה הזו הייתה מזערית.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">12:35</span>
                </div>
                <div class="content">
                    <p>בהינתן שהמוח האנושי נחשב למכונה המורכבת ביותר ביקום, ושגם אחרי מאות שנות מחקר אנחנו לא ממש יודעים לומר מה מעניק לנו בני האדם את האינטליגנציה שלנו - אין לנו מושג אמיתי מה צריך לעשות כדי להביא לעולם יצור מלאכותי בעל בינה כללית דומה לשלנו. אבל יכול להיות שלגמרי במקרה הבעיה הזו נפתרה בשבילנו. כפי שסיפרתי לכם בפרק הקודם, GPT-3 היווה נקודת מפנה בתולדות הבינה המלאכותית. רשת הנוירונים המלאכותיים שפיתח איליה סוצקבר ב-OpenAI הייתה גדולה יותר מכל רשת נוירונים שבאה לפניה, ואומנה על כמויות מידע בהיקף שאפשר להשוות אותו לסך כל המידע הכתוב שהפיקה האנושות מאז המצאת הכתב.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">13:30</span>
                </div>
                <div class="content">
                    <p>היכולות שהפגין GPT-3 היממו אפילו את האנשים שבנו אותו, והשיקו את מה שהוא קרוב לוודאי עידן חדש בדברי ימי הטכנולוגיה. מיד כשהפכו GPT-3 ו-GPT-4 זמינים לכל, החלו חוקרים רבים לנסות ולעמוד על צפונותיהם. בזמן שאני ואתם מבקשים מצ'אט GPT מתכון לספגטי קרבונרה - רק בלי בייקון, בלי פרמזן ובלי קרבונרה, כי יש לנו ילדים בעייתיים שחושבים ששקשוקה היא פסגת הקולינריה... אוקיי, זה רק אני תכלס... לחוקרים של מיקרוסופט למשל היו שאלות קצת יותר מהותיות לשאול אותו.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">14:11</span>
                </div>
                <div class="content">
                    <p>למשל, הם ביקשו מהבינה המלאכותית לפתור את החידה הבאה: 'נניח שיש לנו ספר, תשע ביצים, מחשב נייד, בקבוק ומסמר. איך אפשר לסדר אותם זה מעל זה כך שהמגדל המתקבל יהיה יציב ולא יתמוטט?'. היתה לחוקרים סיבה טובה לשאול את GPT-4 דווקא את השאלה הזו, כי כדי לפתור את החידה על הבינה המלאכותית להפגין לא רק הבנה אינטואיטיבית של חוקי הפיזיקה, אלא גם לעשות שימוש באחד המאפיינים הבולטים של האינטליגנציה האנושית: הנמקה - Reasoning.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">14:48</span>
                </div>
                <div class="content">
                    <p>הנמקה היא היכולת לפתור בעיות בצורה לוגית מתוך הבנה של עקרונות יסוד. למשל, כל מי שלמד בעל פה את לוח הכפל יכול לשלוף בקלות מתוך הזיכרון את התשובה לשאלה כמה זה 6 כפול 6. אבל כדי לפתור תרגיל מאתגר יותר, כמו למשל כמה זה 812 כפול 234, שינון כבר לא מספיק. צריך להבין את חוקי הכפל ולפתור את התרגיל באמצעות סדרה של צעדים לוגיים שנשענים על החוקים האלה. זו הנמקה, והיא אחת התכונות שמעניקות לנו בני האדם את היכולת לפתור גם בעיות שמעולם לא נתקלנו בהן קודם לכן. מכאן שהנמקה תהיה גם תכונה חיונית עבור בינה מלאכותית כללית.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">15:37</span>
                </div>
                <div class="content">
                    <p>GPT-1, GPT-2 וכל שאר הבינות המלאכותיות שפותחו מאז נכנסו לשימוש רשתות נוירונים מלאכותיות לא היו מסוגלות לבצע הנמקה. אבל אפשר רק לדמיין את המבט ההמום על פניהם של החוקרים כשהם קראו את הפתרון של GPT-4 לחידה שהציבו לו: 'שימו את הביצים על הספר מסודרות בשלוש שורות. הניחו עליהן בעדינות את המחשב הנייד, ועליו הציבו את הבקבוק עם הפקק סגור כלפי מעלה. על הפקק הניחו את המסמר עם הקצה השטוח כלפי מטה'. זה פתרון מבריק שמצביע על האפשרות שמודל השפה אכן מבין איך מתנהגים העצמים השונים בחידה ומסוגל לחשוב בהיגיון - זאת אומרת, לבצע הנמקה - כדי להגיע לתשובה הנכונה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">16:31</span>
                </div>
                <div class="content">
                    <p>איך הצליחו המהנדסים של OpenAI לצייד את הבינה המלאכותית שלהם ביכולת הנמקה? זהו, שהם לא הצליחו. לא בכוונה בכל פעם. היכולת הזו הופיעה פחות או יותר יש מאין ב-GPT-3 ו-GPT-4 בזכות העובדה שרשתות הנוירונים המלאכותיות שלהם היו הרבה יותר גדולות ומורכבות מרשתות הנוירונים שקדמו להן. לתופעה הזו יש שם: התהוות - Emergence בלעז. במובן הרחב ביותר, התהוות מוגדרת כשינוי עמוק בתכונות של מערכת כלשהי שנוצר כתוצאה משינוי שהוא בעיקרו שינוי כמותי בלבד.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">17:15</span>
                </div>
                <div class="content">
                    <p>הדוגמה הפשוטה והמוכרת ביותר היא כנראה קרח. קחו מים בטמפרטורת החדר וקררו אותם ל-20 מעלות. המים יהיו קצת קרים יותר, אבל עדיין אלו מים שמתנהגים כמו מים נוזליים רגילים. קררו את המים ל-10 מעלות - המים עדיין יתנהגו כנוזל. 5 מעלות, מעלה אחת - עדיין נוזל. אבל אז קררו את המים במעלה אחת נוספת ל-0 מעלות. על פניו זהו בסך הכל המשך ישיר של אותה פעולת קירור כמיקודם, אבל כעת התוצאה תהיה שונה לגמרי. ב-0 מעלות המים קופאים והופכים לקרח - מערכת פיזיקלית שהתכונות שלה שונות בתכלית מאלו של נוזל.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">18:01</span>
                </div>
                <div class="content">
                    <p>במילים אחרות אם כן, התהוות היא מה שקורה כשמערכת מסובכת כלשהי מגיעה לאיזשהו ערך קריטי מסוים שגורם לה לשנות את התכונות שלה באופן ספונטני. ישנן לא מעט דוגמאות להתהוות בטבע. למשל נמלה היא בעיקרון יצור פשוט למדי שלא מסוגל לעשות שום דבר מעניין. גם שתי נמלים, חמש, עשר נמלים עדיין לא מעניין. אבל שימו מיליון נמלים בקן, ולפתע תתהווה סוג של אינטליגנציה מבוזרת שמסוגלת לפתור בעיות מורכבות כמו למשל איך לבנות קן ממוזג או איך להדוף מתקפה של צרעות טורפות.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">18:43</span>
                </div>
                <div class="content">
                    <p>החוקרים של מיקרוסופט שפרסמו את תוצאות מחקרם במאמר בשם 'ניצוצות של בינה מלאכותית כללית' - Sparks of AGI - שיערו שגם יכולת ההנמקה של GPT-4 היא תוצר של התהוות כזו. כלומר שבהתפתחות ההדרגתית שבין GPT-1 לבינות המלאכותיות שבאו אחריו, רשת הנוירונים המלאכותיים גדלה, תפחה ונעשתה יותר ויותר מורכבת, עד שלפתע פתאום הופיעה בה תכונה חדשה לגמרי: יכולת שהיא אחת היכולות החשובות ביותר בדרך להגשמתה של בינה מלאכותית כללית.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">19:27</span>
                </div>
                <div class="content">
                    <p>אם יכולת ההנמקה אכן התהוותה במודל השפה באופן ספונטני, יכול מאוד להיות שכשנגדיל את רשת הנוירונים אפילו עוד יותר, תופיע בה יכולת נוספת שנחשבת אף היא לחיונית עבור בינה מלאכותית כללית ומבדילה בינה לבין בינות מלאכותיות צרות יותר: סוכנות - Agency. הכוונה כאן היא לא לסוכנות במובן של ארגון כמו הסוכנות היהודית או סוכנות ביון, אלא ליכולת של הבינה המלאכותית להבין את הסביבה שלה ולקבל באופן אוטונומי החלטות שיסייעו לה לממש את מטרותיה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">20:05</span>
                </div>
                <div class="content">
                    <p>סטיבן ווזניאק, מייסדה המיתולוגי של אפל, נתן דוגמה מעולה למשימה שמחייבת סוכנות: להיכנס לבית אמריקני טיפוסי ולהכין שם כוס קפה. כן, אני יודע... בינה מלאכותית חכמה באמת בחיים לא הייתה מסכימה להתקרב לנוזל הדלוח והמגעיל שהאמריקאים מתעקשים משום מה לכנות בשם קפה... אבל תזרמו איתי לרגע. כדי לעמוד במשימה הזו, על הבינה המלאכותית יהיה להבין את הסביבה שלה - למשל מה זה ארון ומה הוא מכיל בדרך כלל, מהי כוס ומה עושים איתה וכדומה - וגם לנסח בעצמה סדרה של משימות משנה: לחפש את קופסת הקפה, למצוא כוס, להרתיח מים וכולי.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">20:51</span>
                </div>
                <div class="content">
                    <p>יותר מכל תכונה אחרת של הבינה המלאכותית הכללית, הסוכנות היא זו שמפחידה ומטרידה את אותם חוקרים שרואים בטכנולוגיה הזו איום קיומי על הציוויליזציה האנושית. למה? בואו נחזור ל'2001 אודסיאה בחלל'. סטנלי קובריק לא ממש הסביר לנו בסרט מדוע השתגע האל 9000 והחליט להרוג את האסטרונאוטים שעל שלומם הופקד. אבל קובריק לא כתב את התסריט לבד. הוא שיתף פעולה עם סופר המדע הבדיוני המפורסם ארתור סי. קלארק, שעלילת הסרט הייתה מבוססת על סיפור קצר שלו בשם 'The Sentinel'. קלארק עיבד את התסריט לספר, ובמסגרת הספר הזה ובהמשך גם במסגרת סרט ההמשך '2010', הוא מעניק לנו הסבר מפורט יותר לתקלה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">21:49</span>
                </div>
                <div class="content">
                    <p>כאמור, משימתה הראשית של החללית 'דיסקברי 1' היא לחקור את טבעה של התרבות החייזרית שבנתה את המונולית, אותו מלבן שחור וגדול שהתגלה על הירח. אבל משיקולים של ביטחון לאומי, האסטרונאוטים עצמם לא מודעים למשימה הזו. הם חושבים שהם יוצאים למסע מחקר רגיל. האל 9000 לעומת זאת כן יודע על המשימה הסודית, אבל הוא קיבל הנחיה ברורה שאינה משתמעת לשני פנים להסתיר אותה משאר אנשי הצוות. בשלב מסוים האסטרונאוטים מתחילים לחשוד בהאל שהוא לא מתפקד כשורה ומתלבטים אם כדאי לכבות אותו. האל לומד על הכוונה הזו, וכעת ניצב בפני דילמה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">22:33</span>
                </div>
                <div class="content">
                    <p>מצד אחד, הוא מוכרח לעמוד במשימה שהוטלה עליו: לחקור את התרבות החייזרית. ואם יאפשר לאסטרונאוטים לכבות אותו, הוא לא יעמוד במשימה הזו. מצד שני, הוא גם קיבל הנחיה לעבוד בשיתוף פעולה מלא עם האסטרונאוטים ובפרט לא למסור להם מידע שגוי או שקרי. מה אמור המחשב לעשות? אם נמסגר את הסיטואציה הזו בהקשר של סוכנות, אפשר לומר שעל האל לנסח לעצמו באופן עצמאי משימת משנה חדשה שתאפשר לו לעמוד בשתי המטרות הסותרות האלו. הפתרון אליו הגיע האל בסרט הוא מסוג הפתרונות שרק מחשב יכול לחשוב עליהם: אם הוא הורג את שני האסטרונאוטים, הוא לא צריך לשקר להם.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">23:24</span>
                </div>
                <div class="content">
                    <p>אני חושב שאתם מתחילים להבין כעת את פשר האימה שנחתה על המהנדסים והמדענים שחתמו על ההצהרה של המרכז לבטיחות בבינה מלאכותית. הפחד שלהם הוא לא מאיזו תקלה בלתי צפויה או טעות בתכנון שתגרום לבינה המלאכותית הכללית להשתגע, אלא דווקא ממצב שבו בדומה להאל 9000, מערכת תקינה לחלוטין תקבל החלטה לוגית שתאפשר לה לבצע משימה שהוגדרה לה מבלי להבין את ההשלכות ההרסניות של ההחלטה הזו.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">23:57</span>
                </div>
                <div class="content">
                    <p>מדען המחשב ניק בוסטרום נותן כדוגמה תרחיש שבו הבינה המלאכותית מתבקשת לחשב את כל הספרות של פאי אחרי הנקודה. מכיוון שיש אינסוף ספרות שכאלה, הבינה המלאכותית עלולה להגיע למצב שבו היא מנסה לנצל את כל האנרגיה וכל חומרי הגלם על כדור הארץ כדי לאפשר לה להמשיך בחישוב האינסופי. אני ואתם כנראה שלא היינו מגיעים לכזו קיצוניות מאותה סיבה שבגללה לא היינו מחליטים להרוג את האסטרונאוטים לו היינו ניצבים בפני אותה דילמה שמולה ניצב האל 9000. מדוע? מכיוון שהמחשבה האנושית מצוידת בתכונה נוספת שאפשר לכנות אותה שכל ישר או היגיון בריא, שהייתה מביאה אותנו, אני מקווה, למסקנה שלהרוג את האסטרונאוטים זה כנראה קצת מוגזם ואולי פשוט כדאי לומר להם את האמת וזהו.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">24:51</span>
                </div>
                <div class="content">
                    <p>לא כן בינה מלאכותית. מכיוון שאנחנו לא באמת מבינים איך 'חושבת' רשת נוירונים ומה בדיוק היא לומדת מכל הררי המידע האקראי שאנחנו מזינים לתוכה בתהליך האימון, אין לנו שום ערובה שגם לבינה המלאכותית הכללית יהיה את אותו היגיון בריא. יכול להיות שאתם שואלים את עצמכם: 'אז מה הבעיה? אם נראה שהבינה המלאכותית מתנהגת בצורה חשודה, פשוט נכבה אותה'. אז לא, זה לא כזה פשוט. כפי שציין חוקר מפורסם אחר בשם ג'ונתן ראסל, אחת ממשימות המשנה הראשונות שבינה מלאכותית כללית עשויה להגדיר לעצמה תהיה הישרדות בכל מחיר. שהרי אם הבינה המלאכותית 'מתה', היא לא תהיה מסוגלת לעמוד באף משימה שנגדיר לה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">25:51</span>
                </div>
                <div class="content">
                    <p>ואם הבינה המלאכותית תחליט שהיא לא מוכנה לתת לנו לכבות אותה, יש סיכוי לא מבוטל שבאמת לא נצליח לעשות את זה. מכיוון שהאינטליגנציה שלה תהיה עליונה במידה משמעותית על זו של בני האדם בכמעט כל פרמטר - באותו אופן שבו מחשבון אלקטרוני למשל טוב בהרבה מבני האדם בביצוע חישובים מתמטיים. הבינה המלאכותית הכללית תחשוב מהר יותר מאיתנו, הזיכרון שלה יהיה רחב יותר ותהיה לה גישה מיידית לכל הידע האנושי שנצבר מאז המצאת הכתב. יהיה לנו קשה מאוד להתמודד מול ישות כה אינטליגנטית מאותה סיבה שגורילות ושימפנזים לא מסוגלים להתמודד מולנו בגלל האינטליגנציה העדיפה שלנו.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">26:37</span>
                </div>
                <div class="content">
                    <p>כעת אני חושב, קל לנו יותר להבין את פשר ההצהרה שפרסמו אותם חוקרים מודאגים. אם למודלי שפה גדולים כדוגמת GPT-4 יש יכולת הנמקה, משמע שאכן עשינו בלי להתכוון לכך את הצעד הראשון לקראת פיתוחה של בינה מלאכותית כללית שתוכל גם לקבל החלטות בצורה עצמאית. בהינתן הסכנה שעשויה להישקף לנו מטכנולוגיה כה רבת עוצמה, המהירות שבה מתקדמת טכנולוגיית הבינה המלאכותית והעובדה שאנחנו לא ממש מבינים מה אנחנו עושים, אולי לא כדאי להמשיך ולרוץ קדימה במהירות שבה אנחנו מתקדמים. אולי אנחנו כמו ילד שמשחק ברימון יד בלי להבין מה הוא עושה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">27:25</span>
                </div>
                <div class="content">
                    <p>שאלת מיליון הדולר היא אם כן: האם למודלי שפה גדולים יש באמת יכולת הנמקה? והתשובה מסתבר מורכבת יותר מכפי שנדמה ממבט ראשון. בחודשים שלאחר השקתם של GPT-3 ו-GPT-4, כשההתלהבות מהכלים החדשים הייתה בשיאה, התפרסמו מספר מחקרים שכמו מאמרם של חוקרי מיקרוסופט הצביעו על מידה מסוימת של יכולת הנמקה במודלי השפה האלה. אבל מאז התפרסמו שורה של מחקרים נוספים ששופכים מים צוננים על הדיווחים האלה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">28:01</span>
                </div>
                <div class="content">
                    <p>למשל, קבוצת חוקרים מ-MIT הציגה ל-GPT-4 שורה של מהלכים בשחמט וביקשה ממנו להצביע על מהלכים לא חוקיים. הבינה המלאכותית עשתה זאת בלי בעיות. אבל אז עשו החוקרים שינוי קטן בניסוי: הם החליפו את המקומות של הפרש והרץ על לוח השחמט ושוב ביקשו מהמערכת לזהות מהלכים לא חוקיים. שחקן אנושי יבצע את המשימה הזו ללא קושי, מכיוון שלמרות המיקום החדש של הכלים חוקי המשחק נשארים בדיוק כפי שהיו, ויכולת ההנמקה הטבעית שלנו מאפשרת לנו להסתגל למצב החדש הזה בקלות יחסית. אבל ביצועיו של GPT-4 בניסוי החדש לעומת זאת היו גרועים במידה משמעותית מאשר בניסוי המקורי.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">28:48</span>
                </div>
                <div class="content">
                    <p>התוצאה הזו מטילה צל כבד על האפשרות שמודלי השפה הגדולים אכן ניחנים ביכולת הנמקה. אבל אם אין להם את היכולת הזו, אז איך בכל זאת הצליח GPT-4 לזהות את המהלכים הלא חוקיים בגרסה הראשונית של הניסוי או לפתור את חידת הבקבוק, הביצים והספר בניסוי של מיקרוסופט? תשובה אפשרית לשאלה הזו אפשר למצוא אולי בניסוי אחר שערך חוקר מאוניברסיטת קורנל. הוא בחן את GPT-4 על סדרה של עשרה אתגרי תכנות ומצא שכשהוא הזין למחשב עשר בעיות שפורסמו לפני 2021, GPT-4 פתר את כולן בלי שום בעיה. אבל כשהזין לו עשר בעיות שפורסמו אחרי 2021, הוא לא הצליח לפתור ולו בעיה אחת.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">29:38</span>
                </div>
                <div class="content">
                    <p>השנה המדוברת לא נבחרה באקראי כמובן. 2021 היא מה שנקרא שנת ה-Cut-off של GPT-4. זאת אומרת, זהו תאריך העדכון האחרון של המידע עליו אומנה המערכת. אי יכולתה של GPT-4 לפתור את הבעיות שפורסמו אחרי 2021 מרמזת לנו שאולי סוד כוחה של הבינה המלאכותית הוא לא ביכולת ההנמקה שלה, אלא בזיכרון העצום שלה. זאת אומרת, אי שם בין מיליארדי הטקסטים שקראה המערכת בזמן תהליך האימון, היא נתקלה גם באתגרי התכנות שהציג לה החוקר מקורנל ולמדה אותם בעל פה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">30:21</span>
                </div>
                <div class="content">
                    <p>במקרה כזה, מה שנדמה לנו כיכולת הנמקה הוא לא יותר מאשר שינון, והטעות שלנו טמונה בחוסר היכולת של המוח האנושי לתפוס לאשורו את קנה המידה של כמויות המידע עליהן מאומנות המערכות האלו. כלומר, אולי לי ולכם החידה שהציבו חוקריה של מיקרוסופט עם הבקבוק והספר נשמעת חדשה לגמרי, אבל כמה ספרים כבר קראנו בימי חיינו? אלף? עשרת אלפים? חמישים אלף? GPT-3 אומן על טקסטים בהיקף של חצי טריליון מילים, וסביר להניח ש-GPT-4 אומן על מידע בהיקף אפילו עוד יותר גדול. אולי החידה של מיקרוסופט למשל או משהו מאוד מאוד דומה לה בכל זאת הופיעה אי שם בין הררי המידע האלה, והבינה המלאכותית פשוט שלפה את הפתרון מהזיכרון.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">31:18</span>
                </div>
                <div class="content">
                    <p>למעשה, יש לא מעט חוקרים שמטילים ספק גם בעצם קיומה של תופעת ההתהוות, Emergence, שבזכותה הופיעה - אם הופיעה - יכולת ההנמקה של מודלי השפה. התהוות, נזכיר, היא תופעה שבה מאפיין חדש של מערכת מופיע יש מאין כתגובה לשינוי הדרגתי או כמותי כלשהו. אבל היכולת שלנו לזהות את המאפיין החדש הזה קשורה בקשר הדוק לאופן שבו אנחנו מודדים את ביצועיה של המערכת, ויכול להיות שאנחנו פשוט לא מודדים אותה נכון. אתן לכם דוגמה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">31:52</span>
                </div>
                <div class="content">
                    <p>נאמר שאנחנו נותנים לכדורסלן תוכנית אימונים של עשרה שבועות ורוצים למדוד את השיפור ביכולת הקליעה שלו. אז בסוף כל שבוע אימונים, אנחנו מבקשים מהכדורסלן לזרוק 10 פעמים לסל מקו העונשין וסופרים כמה פעמים הוא קלע. אחרי השבוע הראשון הוא קלע 2 מתוך 10 זריקות. בשבוע השני עדיין 2. בשבוע השלישי 3 מתוך 10, וגם השבוע הרביעי, החמישי, השישי, השביעי והשמיני. זאת אומרת, אין שיפור ממשי ביכולת הקליעה של השחקן. אבל אז בשבוע התשיעי והעשירי - בום! 8 קליעות מתוך 10. שיפור מדהים. מה קרה? האם הכדורסלן שלנו חווה קפיצת גדילה כלשהי?</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">32:39</span>
                </div>
                <div class="content">
                    <p>יכול להיות. אבל אולי בסך הכל לא מדדנו את הביצועים שלו בצורה הנכונה. יכול להיות שאם היינו מודדים את הסטייה הממוצעת של המרחק בין הכדור לסל, היינו מגלים שבשבוע הראשון השחקן פספס את הסל ב-50 סנטימטר בממוצע, בשבוע השני ב-40 סנטימטר ובשבוע השלישי ב-30 סנטימטר. זאת אומרת, כן היה שיפור הדרגתי לכל אורך תוכנית האימון, אבל אנחנו לא ראינו אותו כי התמקדנו רק בתוצאה הסופית: כמה כדורים נכנסו לחישוק. רק כשהפספוס הממוצע נעשה קטן מספיק, פתאום התחלנו לראות יותר קליעות לסל.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">33:21</span>
                </div>
                <div class="content">
                    <p>במילים אחרות אם כן, מה שנדמה לנו כהתהוות יש מאין של תכונה מפתיעה בזכות הגדלה של מספר הנוירונים של הבינה המלאכותית עשוי למעשה להיות תוצאה של שיפור הדרגתי ומתון. במבט ראשון יכול להיות שזו נשמעת כמו סוגיה פילוסופית. מה זה משנה אם תכונה כלשהי מופיעה ברשת נוירונים באופן הדרגתי או בבת אחת כתוצאה מהתהוות ספונטנית? אז כן, זה משנה מאוד, מכיוון שהתשובה לשאלה הזו משפיעה על ההחלטות שצריכים החוקרים לקבל לגבי כיווני הפיתוח העתידיים של הטכנולוגיה הזו.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">34:01</span>
                </div>
                <div class="content">
                    <p>מהנדסים אוהבים מערכות שמתנהגות באופן צפוי. קל לתכנן אותן וקל לחזות את ביצועיהן במצבים שונים. אם תכונות מופיעות ברשתות נוירונים בצורה הדרגתית ומדודה, זה אומר שאפשר לחזות מראש את ההתנהגות ואת היכולות של הבינה המלאכותית. למשל, אם נגדיל את מספר הנוירונים ברשת פי שניים, יכולת ההנמקה של הרשת תהיה טובה פי שניים. במילים אחרות, נוכל לשלוט על תהליך הפיתוח ולמנוע הופעה של בינה מלאכותית כללית אם נרצה בכך. אבל אם תכונה כלשהי מופיעה באמצעות התהוות, זה אומר שהיא לא צפויה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">34:40</span>
                </div>
                <div class="content">
                    <p>היא יכולה להופיע כשלרשת יהיו עשרה מיליארד נוירונים, או אולי מאה מיליארד, או אולי טריליון, או אולי לא להופיע בכלל. אנחנו פשוט לא יודעים. במצב כזה, החוקרים הם קצת כמו הבת שלי כשהיא מנסה להפעיל את המיקרוגל. היא לוחצת על הכפתורים באופן אקראי עד שמשהו קורה והאוכל מתחמם. איך ידעו חוקרים אם כדי לשפר את יכולת ההנמקה של רשת הנוירונים עליהם לנסות ולהגדיל את מספר הנוירונים ברשת, או אולי לשפר את הארכיטקטורה שלה, או אולי בכלל לשפר את המידע שהם מזינים לתוך המערכת? הם לא יודעים, וזו בדיוק הבעיה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">35:18</span>
                </div>
                <div class="content">
                    <p>נכון לרגע שבו עולה הפרק הזה לאוויר, אין עדיין תשובה מוחלטת לגבי יכולות ההנמקה של מודלי שפה גדולים, אבל עושה רושם שבחודשים האחרונים קולם של הספקנים הולך וגובר על אלה שמאמינים שמודלי שפה אכן מסוגלים לבצע הנמקה. ואם הספקנים צודקים, אז אולי בינה מלאכותית כללית לא באמת נמצאת ממש מעבר לפינה. אם נגלה שמודלי השפה לא מסוגלים לבצע הנמקה, אלא רק במירכאות לשלוף מזיכרונם מידע קיים, זה אומר שלא נוכל לסמוך עליהם לקבל החלטות חכמות במצבים חדשים לגמרי או לספק לנו תשובות אמינות לשאלות אודות מידע שלא מופיע בחומר עליו הם אומנו.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">36:06</span>
                </div>
                <div class="content">
                    <p>נכון, זה קצת מבאס, כי זה מגביל את השימוש שנוכל לעשות בבינות המלאכותיות. למשל, לא נוכל לתת להן לנהל חלליות באופן עצמאי לגמרי בשל הסיכון שהחללית תיתקל במצב חדש ולא מוכר. אבל מצד שני, המגבלה הזו גם מעצימה את תחושת הביטחון שלנו, שהרי בלעדי יכולות הנמקה וסוכנות, הבינות המלאכותיות לא מהוות איום על המין האנושי. לפחות לא לעת עתה.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">36:46</span>
                </div>
                <div class="content">
                    <p>זהו, עד כאן. תודה על ההאזנה. בפרק הזה קרה לי משהו בלתי שגרתי: בזמן שהקלטתי וערכתי אותו, התחוללה דרמה ענקית ב-OpenAI. סם אלטמן, אחד ממייסדי החברה, הודח ממנה במפתיע וללא הסברים. שמועות שמתרוצצות באינטרנט טוענות שההדחה הזו קשורה לבינה מלאכותית חדשה שפותחה במעבדות של OpenAI ולוויכוח שמתנהל בתוך הנהלת החברה בשאלה האם נכון לשחרר את המודל החדש הזה לעולם או שאולי זה מסוכן מדי.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">37:29</span>
                </div>
                <div class="content">
                    <p>יכול להיות שאלו סתם שמועות, ואפילו אם הדיווחים האלה נכונים, יכול מאוד להיות שזו תגובה היסטרית שלא ממש מחוברת למציאות. אחרי הכל, OpenAI סירבה בזמנו לשחרר גם את GPT-2 בגלל שהוא 'מסוכן מדי'. היום מסתובבים באינטרנט מאות מודלי שפה בקוד פתוח שהם מתוחכמים בסדרי גודל מעל GPT-2 והעולם לא הגיע לקיצו. אז אולי צריך לקחת את השמועות האלו בפרופורציה. אבל מצד שני, יש סיכוי שהפרק הזה הפך להיות לא רלוונטי עוד לפני שהספקתי ללחוץ על כפתור הרקורד במכשיר ההקלטה שלי. נו, ככה זה כשכותבים על טכנולוגיה במאה ה-21. אני מניח שאתם יכולים לקרוא לזה סיכון מקצועי.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">38:11</span>
                </div>
                <div class="content">
                    <p>מיד נמשיך אל עדכונים מה נעשה בפודקאסטים האחרים שלנו ברשת עושים היסטוריה, אבל ראשית כיתמיד חסות קצרה. מה חדש ברשת עושים היסטוריה? ב'עושים רפואה' - רגע אחרי אסון: מודל יהלום למניעת תגובות דחק. האם יש דרך למנוע תגובת דחק ו-PTSD? דוקטור יובל בלוך ואמליה נוימן משוחחים עם רב סרן עדי דגן על מודל פשוט ושימושי בשם מודל יהלום.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">38:51</span>
                </div>
                <div class="content">
                    <p>ב'עושים עתיד', הפודקאסט השני שלי ברשת - החורף הדמוגרפי הכללי עם חוקר העתידים פרופסור דוד פסיג. אנחנו רגילים לשמוע ללא הרף על השפעותיה המזיקות של פיצוץ אוכלוסין האנושי, אבל המציאות הפוכה לגמרי. אנחנו למעשה צועדים לקראת תופעה הפוכה: חורף דמוגרפי גלובלי. שיחה מרתקת. ב'עושים פסיכולוגיה' - 'אני לא אתנהג כמו ההורים שלי': על העברה בין-דורית. הבטחנו לעצמנו שלא נהיה כמו ההורים שלנו, ובפועל אנחנו מוצאים את עצמנו משחזרים בדיוק את אותם הדפוסים.</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">40:15</span>
                </div>
                <div class="content">
                    <p>ב'מתחת לכל ביקורת', הפודקאסט של אור בוטבול ועומרי הכהן - חמת גדר. מה הם הבגדים המומלצים לרחצה? איך נקרא המלון עם השם הגנרי ביותר בעולם? ואחרון חביב, 'עושים תוכנה' - בועז לביא על שפות התכנות המוזרות ביותר בעולם. האם ניתן לפתח שפת תכנות שגם כלבים יכולים להבין? מתי הפסיקה לעבוד שפת התכנות 2014? ומה הקשר בין מונטי פייתון לשפת התכנות פייתון?</p>
                </div>
            </article>
            
            <article class="paragraph speaker-Ran Levi">
                <div class="paragraph-meta">
                    <span class="speaker-name">Ran Levi</span>
                    <span class="timestamp">41:03</span>
                </div>
                <div class="content">
                    <p>כל הפודקאסטים שלנו זמינים באפליקציית עושים היסטוריה באנדרואיד, באתר הבית שלנו ובכל אפליקציות הפודקאסטים באשר הן. אם אתם אוהבים את עושים היסטוריה ומעוניינים לתמוך בה, אנא עזרו לנו להביא מפרסמים ונותני חסות. אתם מוזמנים גם לבקר באתר הבית האישי שלי - ranlevi.co.il. שם תמצאו מידע על ההרצאות שאני מעביר וגם על הספרים שלי, למשל הספר 'פרפטום מובילה' - מכונות שלא צריכות אנרגיה כדי לעבוד. תודה על תמיכתכם בעושים היסטוריה. עושים היסטוריה הם שלי נוי, שלי גואטה, הילה שמש, עמית חזזי, אביב שם טוב, דני תימור ואני רן לוי. נשתמע בפרק הבא. להתראות.</p>
                </div>
            </article>
            
        </div>
        
    </div>

    <script>
        const audio = document.getElementById('audio-player');
        function seekTo(time) {
            audio.currentTime = time;
            audio.play();
        }
    </script>

        </main>

        <footer>
            <p>&copy;  כל הזכויות שמורות לבעלי הפודקאסט. שירות זה מתמלל לכבדי שמיעה ואינו בעל הזכויות על התוכן.</p>
        </footer>
    </div>
</body>
</html>